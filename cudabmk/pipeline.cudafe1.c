# 1 "pipeline.cu"
# 1006 "/usr/local/cuda4.1/cuda/include/driver_types.h"
struct CUstream_st;
# 206 "/usr/include/libio.h" 3
enum __codecvt_result {

__codecvt_ok,
__codecvt_partial,
__codecvt_error,
__codecvt_noconv};
# 271 "/usr/include/libio.h" 3
struct _IO_FILE;
# 203 "/usr/include/math.h" 3
enum _ZUt_ {
FP_NAN,

FP_INFINITE,

FP_ZERO,

FP_SUBNORMAL,

FP_NORMAL};
# 296 "/usr/include/math.h" 3
enum _LIB_VERSION_TYPE {
_IEEE_ = (-1),
_SVID_,
_XOPEN_,
_POSIX_,
_ISOC_};
# 124 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_voidIvEUt_E { _ZNSt9__is_voidIvE7__valueE = 1};
# 144 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIbEUt_E { _ZNSt12__is_integerIbE7__valueE = 1};
# 151 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIcEUt_E { _ZNSt12__is_integerIcE7__valueE = 1};
# 158 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIaEUt_E { _ZNSt12__is_integerIaE7__valueE = 1};
# 165 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIhEUt_E { _ZNSt12__is_integerIhE7__valueE = 1};
# 173 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIwEUt_E { _ZNSt12__is_integerIwE7__valueE = 1};
# 197 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIsEUt_E { _ZNSt12__is_integerIsE7__valueE = 1};
# 204 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerItEUt_E { _ZNSt12__is_integerItE7__valueE = 1};
# 211 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIiEUt_E { _ZNSt12__is_integerIiE7__valueE = 1};
# 218 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIjEUt_E { _ZNSt12__is_integerIjE7__valueE = 1};
# 225 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIlEUt_E { _ZNSt12__is_integerIlE7__valueE = 1};
# 232 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerImEUt_E { _ZNSt12__is_integerImE7__valueE = 1};
# 239 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIxEUt_E { _ZNSt12__is_integerIxE7__valueE = 1};
# 246 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIyEUt_E { _ZNSt12__is_integerIyE7__valueE = 1};
# 264 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIfEUt_E { _ZNSt13__is_floatingIfE7__valueE = 1};
# 271 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIdEUt_E { _ZNSt13__is_floatingIdE7__valueE = 1};
# 278 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt13__is_floatingIeEUt_E { _ZNSt13__is_floatingIeE7__valueE = 1};
# 354 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_charIcEUt_E { _ZNSt9__is_charIcE7__valueE = 1};
# 362 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_charIwEUt_E { _ZNSt9__is_charIwE7__valueE = 1};
# 377 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIcEUt_E { _ZNSt9__is_byteIcE7__valueE = 1};
# 384 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIaEUt_E { _ZNSt9__is_byteIaE7__valueE = 1};
# 391 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt9__is_byteIhEUt_E { _ZNSt9__is_byteIhE7__valueE = 1};
# 134 "/usr/include/c++/4.4/bits/cpp_type_traits.h" 3
enum _ZNSt12__is_integerIfEUt_E { _ZNSt12__is_integerIfE7__valueE};
# 64 "/usr/include/bits/mathinline.h" 3
union _ZZ10__signbitlEUt_;
# 211 "/usr/lib/gcc/x86_64-linux-gnu/4.4.5/include/stddef.h" 3
typedef unsigned long size_t;
#include "crt/host_runtime.h"
# 145 "/usr/include/bits/types.h" 3
typedef long __clock_t;
# 60 "/usr/include/time.h" 3
typedef __clock_t clock_t;
# 49 "/usr/include/stdio.h" 3
typedef struct _IO_FILE FILE;
# 2 "instructions.h"
typedef unsigned UINT;
typedef int INT;
typedef float FLOAT;
typedef double DOUBLE;
# 64 "/usr/include/bits/mathinline.h" 3
union _ZZ10__signbitlEUt_ { long double __l; int __i[3];};
void *memcpy(void*, const void*, size_t); void *memset(void*, int, size_t);
# 664 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaThreadSynchronize(void);
# 887 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaGetLastError(void);
# 942 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern const char *cudaGetErrorString(cudaError_t);
# 1715 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaConfigureCall(dim3, dim3, size_t, cudaStream_t);
# 1933 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaMalloc(void **, size_t);
# 2067 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaFree(void *);
# 2748 "/usr/local/cuda4.1/cuda/include/cuda_runtime_api.h"
extern cudaError_t cudaMemcpy(void *, const void *, size_t, enum cudaMemcpyKind);
# 183 "/usr/include/time.h" 3
extern clock_t clock(void);
# 86 "/usr/include/bits/stdio2.h" 3
extern int __fprintf_chk(FILE *__restrict__, int, const char *__restrict__, ...);

extern int __printf_chk(int, const char *__restrict__, ...);
# 96 "/usr/include/bits/stdio2.h" 3
extern  __attribute__((__weak__)) /* COMDAT group: fprintf */ __inline__ __attribute__((__artificial__)) __attribute__((__always_inline__)) int fprintf(FILE *__restrict__, const char *__restrict__, ...);
# 103 "/usr/include/bits/stdio2.h" 3
extern  __attribute__((__weak__)) /* COMDAT group: printf */ __inline__ __attribute__((__artificial__)) __attribute__((__always_inline__)) int printf(const char *__restrict__, ...);
# 160 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern __attribute__((__const__)) int abs(int);
# 189 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern int min(int, int);
extern unsigned umin(unsigned, unsigned);
# 208 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern float fminf(float, float);
# 224 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern double fmin(double, double);
extern int max(int, int);
extern unsigned umax(unsigned, unsigned);
# 244 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern float fmaxf(float, float);
# 260 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern double fmax(double, double);
# 375 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern float rsqrtf(float);
# 412 "/usr/local/cuda4.1/cuda/include/math_functions.h"
extern float exp2f(float);
# 38 "/usr/include/bits/mathinline.h" 3
extern  __attribute__((__weak__)) /* COMDAT group: __signbitf */ __inline__ __attribute__((__const__)) int __signbitf(float);
# 50 "/usr/include/bits/mathinline.h" 3
extern  __attribute__((__weak__)) /* COMDAT group: __signbit */ __inline__ __attribute__((__const__)) int __signbit(double);
# 62 "/usr/include/bits/mathinline.h" 3
extern  __attribute__((__weak__)) /* COMDAT group: __signbitl */ __inline__ __attribute__((__const__)) int __signbitl(long double);
# 202 "pipeline.cu"
extern void _Z16measure_pipelinev(void);
extern int __cudaSetupArgSimple();
extern int __cudaLaunch();
extern int __cudaRegisterBinary();
extern int __cudaRegisterEntry();
static void __sti___16_pipeline_cpp1_ii_00c5b4ce(void) __attribute__((__constructor__));
# 167 "/usr/include/stdio.h" 3
extern struct _IO_FILE *stderr;
extern  __attribute__((__weak__)) /* COMDAT group: _ZTSSt9exception */ const char _ZTSSt9exception[13] __attribute__((visibility("default")));
extern  __attribute__((__weak__)) /* COMDAT group: _ZTSSt9bad_alloc */ const char _ZTSSt9bad_alloc[13] __attribute__((visibility("default")));
 __attribute__((__weak__)) /* COMDAT group: _ZTSSt9exception */ const char _ZTSSt9exception[13] __attribute__((visibility("default"))) = "St9exception";
 __attribute__((__weak__)) /* COMDAT group: _ZTSSt9bad_alloc */ const char _ZTSSt9bad_alloc[13] __attribute__((visibility("default"))) = "St9bad_alloc";
# 96 "/usr/include/bits/stdio2.h" 3
 __attribute__((__weak__)) /* COMDAT group: fprintf */ __inline__ __attribute__((__artificial__)) __attribute__((__always_inline__)) int fprintf( FILE *__restrict__ __stream,  const char *__restrict__ __fmt, ...)
{
return __fprintf_chk(__stream, 1, __fmt, (__builtin_va_arg_pack()));

}


 __attribute__((__weak__)) /* COMDAT group: printf */ __inline__ __attribute__((__artificial__)) __attribute__((__always_inline__)) int printf( const char *__restrict__ __fmt, ...)
{
return __printf_chk(1, __fmt, (__builtin_va_arg_pack()));
}
# 38 "/usr/include/bits/mathinline.h" 3
 __attribute__((__weak__)) /* COMDAT group: __signbitf */ __inline__ __attribute__((__const__)) int __signbitf( float __x)
{




 int __cuda_local_var_7238_7_non_const___m;
__asm("pmovmskb %1, %0" : "=r" (__cuda_local_var_7238_7_non_const___m) : "x" (__x));
return __cuda_local_var_7238_7_non_const___m & 8;

}

 __attribute__((__weak__)) /* COMDAT group: __signbit */ __inline__ __attribute__((__const__)) int __signbit( double __x)
{




 int __cuda_local_var_7250_7_non_const___m;
__asm("pmovmskb %1, %0" : "=r" (__cuda_local_var_7250_7_non_const___m) : "x" (__x));
return __cuda_local_var_7250_7_non_const___m & 128;

}

 __attribute__((__weak__)) /* COMDAT group: __signbitl */ __inline__ __attribute__((__const__)) int __signbitl( long double __x)
{
 union _ZZ10__signbitlEUt_ __cuda_local_var_7258_56_non_const___u;
# 64 "/usr/include/bits/mathinline.h" 3
(__cuda_local_var_7258_56_non_const___u.__l) = __x;
return (int)(((((__cuda_local_var_7258_56_non_const___u.__i))[2]) & 32768) != 0);
}
# 202 "pipeline.cu"
void _Z16measure_pipelinev(void)
{

 int __cuda_local_var_17012_12_const_kernel_ops;
 unsigned __cuda_local_var_17013_15_non_const_ts[2048];
 unsigned *__cuda_local_var_17014_16_non_const_d_ts;
 unsigned *__cuda_local_var_17015_16_non_const_d_out;


 dim3 __cuda_local_var_17018_11_non_const_Db;
 dim3 __cuda_local_var_17019_11_non_const_Dg;
# 205 "pipeline.cu"
__cuda_local_var_17012_12_const_kernel_ops = 256;
# 211 "pipeline.cu"
{ (__cuda_local_var_17018_11_non_const_Db.x) = 1U; (__cuda_local_var_17018_11_non_const_Db.y) = 1U; (__cuda_local_var_17018_11_non_const_Db.z) = 1U; }
{ (__cuda_local_var_17019_11_non_const_Dg.x) = 1U; (__cuda_local_var_17019_11_non_const_Dg.y) = 1U; (__cuda_local_var_17019_11_non_const_Dg.z) = 1U; }


if (0 != ((int)(cudaMalloc(((void **)(&__cuda_local_var_17014_16_non_const_d_ts)), 8192UL))))
{
printf(((const char *)"cudaMalloc failed %s:%d\n"), ((const char *)("pipeline.cu")), 217);
return;
}
if (0 != ((int)(cudaMalloc(((void **)(&__cuda_local_var_17015_16_non_const_d_out)), 4UL))))
{
printf(((const char *)"cudaMalloc failed %s:%d\n"), ((const char *)("pipeline.cu")), 222);
return;
}

cudaGetLastError();
fprintf(stderr, ((const char *)"Running pipeline tests...\n\n"));



do {  cudaError_t __cuda_local_var_17038_108_non_const_error;
# 231 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_UINT_DEP128"))); if (((int)(__cuda_local_var_17038_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17038_108_non_const_error))); goto __T20; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T20:;
do {  cudaError_t __cuda_local_var_17039_111_non_const_error;
# 232 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17039_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17039_111_non_const_error))); goto __T21; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T21:;
do {  cudaError_t __cuda_local_var_17040_110_non_const_error;
# 233 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17040_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17040_110_non_const_error))); goto __T22; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T22:;
printf(((const char *)"\n"));

do {  cudaError_t __cuda_local_var_17043_164_non_const_error;
# 236 "pipeline.cu"
 unsigned __cuda_local_var_17043_382_non_const_min_t;
# 236 "pipeline.cu"
 unsigned __cuda_local_var_17043_402_non_const_max_t;
# 236 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17043_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17043_164_non_const_error))); goto __T23; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17043_382_non_const_min_t = 4294967295U; __cuda_local_var_17043_402_non_const_max_t = 0U; {  int i;
# 236 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T24;
 unsigned __T25;
# 236 "pipeline.cu"
__cuda_local_var_17043_382_non_const_min_t = ((__T24 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17043_382_non_const_min_t, __T24))); __cuda_local_var_17043_402_non_const_max_t = ((__T25 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17043_402_non_const_max_t, __T25))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17043_402_non_const_max_t - __cuda_local_var_17043_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17043_402_non_const_max_t - __cuda_local_var_17043_382_non_const_min_t)))); } while (0); __T23:;
do {  cudaError_t __cuda_local_var_17044_170_non_const_error;
# 237 "pipeline.cu"
 unsigned __cuda_local_var_17044_388_non_const_min_t;
# 237 "pipeline.cu"
 unsigned __cuda_local_var_17044_408_non_const_max_t;
# 237 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17044_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17044_170_non_const_error))); goto __T26; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17044_388_non_const_min_t = 4294967295U; __cuda_local_var_17044_408_non_const_max_t = 0U; {  int i;
# 237 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T27;
 unsigned __T28;
# 237 "pipeline.cu"
__cuda_local_var_17044_388_non_const_min_t = ((__T27 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17044_388_non_const_min_t, __T27))); __cuda_local_var_17044_408_non_const_max_t = ((__T28 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17044_408_non_const_max_t, __T28))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17044_408_non_const_max_t - __cuda_local_var_17044_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17044_408_non_const_max_t - __cuda_local_var_17044_388_non_const_min_t)))); } while (0); __T26:;
do {  cudaError_t __cuda_local_var_17045_168_non_const_error;
# 238 "pipeline.cu"
 unsigned __cuda_local_var_17045_386_non_const_min_t;
# 238 "pipeline.cu"
 unsigned __cuda_local_var_17045_406_non_const_max_t;
# 238 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17045_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17045_168_non_const_error))); goto __T29; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17045_386_non_const_min_t = 4294967295U; __cuda_local_var_17045_406_non_const_max_t = 0U; {  int i;
# 238 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T210;
 unsigned __T211;
# 238 "pipeline.cu"
__cuda_local_var_17045_386_non_const_min_t = ((__T210 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17045_386_non_const_min_t, __T210))); __cuda_local_var_17045_406_non_const_max_t = ((__T211 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17045_406_non_const_max_t, __T211))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17045_406_non_const_max_t - __cuda_local_var_17045_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17045_406_non_const_max_t - __cuda_local_var_17045_386_non_const_min_t)))); } while (0); __T29:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17049_108_non_const_error;
# 242 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_UINT_DEP128"))); if (((int)(__cuda_local_var_17049_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17049_108_non_const_error))); goto __T212; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T212:;
do {  cudaError_t __cuda_local_var_17050_108_non_const_error;
# 243 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SUB_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_UINT_DEP128"))); if (((int)(__cuda_local_var_17050_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17050_108_non_const_error))); goto __T213; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T213:;
do {  cudaError_t __cuda_local_var_17051_108_non_const_error;
# 244 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MAD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_UINT_DEP128"))); if (((int)(__cuda_local_var_17051_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17051_108_non_const_error))); goto __T214; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T214:;
do {  cudaError_t __cuda_local_var_17052_108_non_const_error;
# 245 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MUL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_UINT_DEP128"))); if (((int)(__cuda_local_var_17052_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17052_108_non_const_error))); goto __T215; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T215:;
do {  cudaError_t __cuda_local_var_17053_108_non_const_error;
# 246 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_DIV_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_UINT_DEP128"))); if (((int)(__cuda_local_var_17053_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17053_108_non_const_error))); goto __T216; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T216:;
do {  cudaError_t __cuda_local_var_17054_108_non_const_error;
# 247 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_REM_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_REM_UINT_DEP128"))); if (((int)(__cuda_local_var_17054_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17054_108_non_const_error))); goto __T217; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T217:;
do {  cudaError_t __cuda_local_var_17055_108_non_const_error;
# 248 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MIN_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_UINT_DEP128"))); if (((int)(__cuda_local_var_17055_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17055_108_non_const_error))); goto __T218; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T218:;
do {  cudaError_t __cuda_local_var_17056_108_non_const_error;
# 249 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MAX_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_UINT_DEP128"))); if (((int)(__cuda_local_var_17056_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17056_108_non_const_error))); goto __T219; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T219:;

do {  cudaError_t __cuda_local_var_17058_164_non_const_error;
# 251 "pipeline.cu"
 unsigned __cuda_local_var_17058_382_non_const_min_t;
# 251 "pipeline.cu"
 unsigned __cuda_local_var_17058_402_non_const_max_t;
# 251 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17058_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17058_164_non_const_error))); goto __T220; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17058_382_non_const_min_t = 4294967295U; __cuda_local_var_17058_402_non_const_max_t = 0U; {  int i;
# 251 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T221;
 unsigned __T222;
# 251 "pipeline.cu"
__cuda_local_var_17058_382_non_const_min_t = ((__T221 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17058_382_non_const_min_t, __T221))); __cuda_local_var_17058_402_non_const_max_t = ((__T222 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17058_402_non_const_max_t, __T222))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17058_402_non_const_max_t - __cuda_local_var_17058_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17058_402_non_const_max_t - __cuda_local_var_17058_382_non_const_min_t)))); } while (0); __T220:;
do {  cudaError_t __cuda_local_var_17059_164_non_const_error;
# 252 "pipeline.cu"
 unsigned __cuda_local_var_17059_382_non_const_min_t;
# 252 "pipeline.cu"
 unsigned __cuda_local_var_17059_402_non_const_max_t;
# 252 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SUB_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17059_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17059_164_non_const_error))); goto __T223; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17059_382_non_const_min_t = 4294967295U; __cuda_local_var_17059_402_non_const_max_t = 0U; {  int i;
# 252 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T224;
 unsigned __T225;
# 252 "pipeline.cu"
__cuda_local_var_17059_382_non_const_min_t = ((__T224 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17059_382_non_const_min_t, __T224))); __cuda_local_var_17059_402_non_const_max_t = ((__T225 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17059_402_non_const_max_t, __T225))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17059_402_non_const_max_t - __cuda_local_var_17059_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17059_402_non_const_max_t - __cuda_local_var_17059_382_non_const_min_t)))); } while (0); __T223:;
do {  cudaError_t __cuda_local_var_17060_164_non_const_error;
# 253 "pipeline.cu"
 unsigned __cuda_local_var_17060_382_non_const_min_t;
# 253 "pipeline.cu"
 unsigned __cuda_local_var_17060_402_non_const_max_t;
# 253 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MAD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17060_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17060_164_non_const_error))); goto __T226; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17060_382_non_const_min_t = 4294967295U; __cuda_local_var_17060_402_non_const_max_t = 0U; {  int i;
# 253 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T227;
 unsigned __T228;
# 253 "pipeline.cu"
__cuda_local_var_17060_382_non_const_min_t = ((__T227 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17060_382_non_const_min_t, __T227))); __cuda_local_var_17060_402_non_const_max_t = ((__T228 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17060_402_non_const_max_t, __T228))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17060_402_non_const_max_t - __cuda_local_var_17060_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17060_402_non_const_max_t - __cuda_local_var_17060_382_non_const_min_t)))); } while (0); __T226:;
do {  cudaError_t __cuda_local_var_17061_164_non_const_error;
# 254 "pipeline.cu"
 unsigned __cuda_local_var_17061_382_non_const_min_t;
# 254 "pipeline.cu"
 unsigned __cuda_local_var_17061_402_non_const_max_t;
# 254 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MUL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17061_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17061_164_non_const_error))); goto __T229; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17061_382_non_const_min_t = 4294967295U; __cuda_local_var_17061_402_non_const_max_t = 0U; {  int i;
# 254 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T230;
 unsigned __T231;
# 254 "pipeline.cu"
__cuda_local_var_17061_382_non_const_min_t = ((__T230 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17061_382_non_const_min_t, __T230))); __cuda_local_var_17061_402_non_const_max_t = ((__T231 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17061_402_non_const_max_t, __T231))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17061_402_non_const_max_t - __cuda_local_var_17061_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17061_402_non_const_max_t - __cuda_local_var_17061_382_non_const_min_t)))); } while (0); __T229:;
do {  cudaError_t __cuda_local_var_17062_164_non_const_error;
# 255 "pipeline.cu"
 unsigned __cuda_local_var_17062_382_non_const_min_t;
# 255 "pipeline.cu"
 unsigned __cuda_local_var_17062_402_non_const_max_t;
# 255 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_DIV_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17062_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17062_164_non_const_error))); goto __T232; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17062_382_non_const_min_t = 4294967295U; __cuda_local_var_17062_402_non_const_max_t = 0U; {  int i;
# 255 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T233;
 unsigned __T234;
# 255 "pipeline.cu"
__cuda_local_var_17062_382_non_const_min_t = ((__T233 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17062_382_non_const_min_t, __T233))); __cuda_local_var_17062_402_non_const_max_t = ((__T234 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17062_402_non_const_max_t, __T234))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17062_402_non_const_max_t - __cuda_local_var_17062_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17062_402_non_const_max_t - __cuda_local_var_17062_382_non_const_min_t)))); } while (0); __T232:;
do {  cudaError_t __cuda_local_var_17063_164_non_const_error;
# 256 "pipeline.cu"
 unsigned __cuda_local_var_17063_382_non_const_min_t;
# 256 "pipeline.cu"
 unsigned __cuda_local_var_17063_402_non_const_max_t;
# 256 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_REM_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_REM_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17063_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17063_164_non_const_error))); goto __T235; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17063_382_non_const_min_t = 4294967295U; __cuda_local_var_17063_402_non_const_max_t = 0U; {  int i;
# 256 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T236;
 unsigned __T237;
# 256 "pipeline.cu"
__cuda_local_var_17063_382_non_const_min_t = ((__T236 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17063_382_non_const_min_t, __T236))); __cuda_local_var_17063_402_non_const_max_t = ((__T237 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17063_402_non_const_max_t, __T237))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17063_402_non_const_max_t - __cuda_local_var_17063_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17063_402_non_const_max_t - __cuda_local_var_17063_382_non_const_min_t)))); } while (0); __T235:;
do {  cudaError_t __cuda_local_var_17064_164_non_const_error;
# 257 "pipeline.cu"
 unsigned __cuda_local_var_17064_382_non_const_min_t;
# 257 "pipeline.cu"
 unsigned __cuda_local_var_17064_402_non_const_max_t;
# 257 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MIN_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17064_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17064_164_non_const_error))); goto __T238; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17064_382_non_const_min_t = 4294967295U; __cuda_local_var_17064_402_non_const_max_t = 0U; {  int i;
# 257 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T239;
 unsigned __T240;
# 257 "pipeline.cu"
__cuda_local_var_17064_382_non_const_min_t = ((__T239 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17064_382_non_const_min_t, __T239))); __cuda_local_var_17064_402_non_const_max_t = ((__T240 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17064_402_non_const_max_t, __T240))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17064_402_non_const_max_t - __cuda_local_var_17064_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17064_402_non_const_max_t - __cuda_local_var_17064_382_non_const_min_t)))); } while (0); __T238:;
do {  cudaError_t __cuda_local_var_17065_164_non_const_error;
# 258 "pipeline.cu"
 unsigned __cuda_local_var_17065_382_non_const_min_t;
# 258 "pipeline.cu"
 unsigned __cuda_local_var_17065_402_non_const_max_t;
# 258 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_MAX_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17065_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17065_164_non_const_error))); goto __T241; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17065_382_non_const_min_t = 4294967295U; __cuda_local_var_17065_402_non_const_max_t = 0U; {  int i;
# 258 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T242;
 unsigned __T243;
# 258 "pipeline.cu"
__cuda_local_var_17065_382_non_const_min_t = ((__T242 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17065_382_non_const_min_t, __T242))); __cuda_local_var_17065_402_non_const_max_t = ((__T243 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17065_402_non_const_max_t, __T243))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17065_402_non_const_max_t - __cuda_local_var_17065_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17065_402_non_const_max_t - __cuda_local_var_17065_382_non_const_min_t)))); } while (0); __T241:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17069_107_non_const_error;
# 262 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_ADD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_INT_DEP128"))); if (((int)(__cuda_local_var_17069_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17069_107_non_const_error))); goto __T244; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T244:;
do {  cudaError_t __cuda_local_var_17070_107_non_const_error;
# 263 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_SUB_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_INT_DEP128"))); if (((int)(__cuda_local_var_17070_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17070_107_non_const_error))); goto __T245; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T245:;
do {  cudaError_t __cuda_local_var_17071_107_non_const_error;
# 264 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MAD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_INT_DEP128"))); if (((int)(__cuda_local_var_17071_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17071_107_non_const_error))); goto __T246; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T246:;
do {  cudaError_t __cuda_local_var_17072_107_non_const_error;
# 265 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MUL_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_INT_DEP128"))); if (((int)(__cuda_local_var_17072_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17072_107_non_const_error))); goto __T247; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T247:;
do {  cudaError_t __cuda_local_var_17073_107_non_const_error;
# 266 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_DIV_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_INT_DEP128"))); if (((int)(__cuda_local_var_17073_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17073_107_non_const_error))); goto __T248; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T248:;
do {  cudaError_t __cuda_local_var_17074_107_non_const_error;
# 267 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_REM_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_REM_INT_DEP128"))); if (((int)(__cuda_local_var_17074_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17074_107_non_const_error))); goto __T249; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T249:;
do {  cudaError_t __cuda_local_var_17075_107_non_const_error;
# 268 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MIN_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_INT_DEP128"))); if (((int)(__cuda_local_var_17075_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17075_107_non_const_error))); goto __T250; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T250:;
do {  cudaError_t __cuda_local_var_17076_107_non_const_error;
# 269 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MAX_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_INT_DEP128"))); if (((int)(__cuda_local_var_17076_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17076_107_non_const_error))); goto __T251; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T251:;
do {  cudaError_t __cuda_local_var_17077_107_non_const_error;
# 270 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_ABS_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ABS_INT_DEP128"))); if (((int)(__cuda_local_var_17077_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17077_107_non_const_error))); goto __T252; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T252:;

do {  cudaError_t __cuda_local_var_17079_162_non_const_error;
# 272 "pipeline.cu"
 unsigned __cuda_local_var_17079_380_non_const_min_t;
# 272 "pipeline.cu"
 unsigned __cuda_local_var_17079_400_non_const_max_t;
# 272 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_ADD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17079_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17079_162_non_const_error))); goto __T253; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17079_380_non_const_min_t = 4294967295U; __cuda_local_var_17079_400_non_const_max_t = 0U; {  int i;
# 272 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T254;
 unsigned __T255;
# 272 "pipeline.cu"
__cuda_local_var_17079_380_non_const_min_t = ((__T254 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17079_380_non_const_min_t, __T254))); __cuda_local_var_17079_400_non_const_max_t = ((__T255 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17079_400_non_const_max_t, __T255))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17079_400_non_const_max_t - __cuda_local_var_17079_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17079_400_non_const_max_t - __cuda_local_var_17079_380_non_const_min_t)))); } while (0); __T253:;
do {  cudaError_t __cuda_local_var_17080_162_non_const_error;
# 273 "pipeline.cu"
 unsigned __cuda_local_var_17080_380_non_const_min_t;
# 273 "pipeline.cu"
 unsigned __cuda_local_var_17080_400_non_const_max_t;
# 273 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_SUB_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17080_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17080_162_non_const_error))); goto __T256; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17080_380_non_const_min_t = 4294967295U; __cuda_local_var_17080_400_non_const_max_t = 0U; {  int i;
# 273 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T257;
 unsigned __T258;
# 273 "pipeline.cu"
__cuda_local_var_17080_380_non_const_min_t = ((__T257 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17080_380_non_const_min_t, __T257))); __cuda_local_var_17080_400_non_const_max_t = ((__T258 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17080_400_non_const_max_t, __T258))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17080_400_non_const_max_t - __cuda_local_var_17080_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17080_400_non_const_max_t - __cuda_local_var_17080_380_non_const_min_t)))); } while (0); __T256:;
do {  cudaError_t __cuda_local_var_17081_162_non_const_error;
# 274 "pipeline.cu"
 unsigned __cuda_local_var_17081_380_non_const_min_t;
# 274 "pipeline.cu"
 unsigned __cuda_local_var_17081_400_non_const_max_t;
# 274 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MAD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17081_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17081_162_non_const_error))); goto __T259; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17081_380_non_const_min_t = 4294967295U; __cuda_local_var_17081_400_non_const_max_t = 0U; {  int i;
# 274 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T260;
 unsigned __T261;
# 274 "pipeline.cu"
__cuda_local_var_17081_380_non_const_min_t = ((__T260 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17081_380_non_const_min_t, __T260))); __cuda_local_var_17081_400_non_const_max_t = ((__T261 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17081_400_non_const_max_t, __T261))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17081_400_non_const_max_t - __cuda_local_var_17081_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17081_400_non_const_max_t - __cuda_local_var_17081_380_non_const_min_t)))); } while (0); __T259:;
do {  cudaError_t __cuda_local_var_17082_162_non_const_error;
# 275 "pipeline.cu"
 unsigned __cuda_local_var_17082_380_non_const_min_t;
# 275 "pipeline.cu"
 unsigned __cuda_local_var_17082_400_non_const_max_t;
# 275 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MUL_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17082_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17082_162_non_const_error))); goto __T262; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17082_380_non_const_min_t = 4294967295U; __cuda_local_var_17082_400_non_const_max_t = 0U; {  int i;
# 275 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T263;
 unsigned __T264;
# 275 "pipeline.cu"
__cuda_local_var_17082_380_non_const_min_t = ((__T263 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17082_380_non_const_min_t, __T263))); __cuda_local_var_17082_400_non_const_max_t = ((__T264 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17082_400_non_const_max_t, __T264))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17082_400_non_const_max_t - __cuda_local_var_17082_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17082_400_non_const_max_t - __cuda_local_var_17082_380_non_const_min_t)))); } while (0); __T262:;
do {  cudaError_t __cuda_local_var_17083_162_non_const_error;
# 276 "pipeline.cu"
 unsigned __cuda_local_var_17083_380_non_const_min_t;
# 276 "pipeline.cu"
 unsigned __cuda_local_var_17083_400_non_const_max_t;
# 276 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_DIV_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17083_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17083_162_non_const_error))); goto __T265; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17083_380_non_const_min_t = 4294967295U; __cuda_local_var_17083_400_non_const_max_t = 0U; {  int i;
# 276 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T266;
 unsigned __T267;
# 276 "pipeline.cu"
__cuda_local_var_17083_380_non_const_min_t = ((__T266 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17083_380_non_const_min_t, __T266))); __cuda_local_var_17083_400_non_const_max_t = ((__T267 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17083_400_non_const_max_t, __T267))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17083_400_non_const_max_t - __cuda_local_var_17083_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17083_400_non_const_max_t - __cuda_local_var_17083_380_non_const_min_t)))); } while (0); __T265:;
do {  cudaError_t __cuda_local_var_17084_162_non_const_error;
# 277 "pipeline.cu"
 unsigned __cuda_local_var_17084_380_non_const_min_t;
# 277 "pipeline.cu"
 unsigned __cuda_local_var_17084_400_non_const_max_t;
# 277 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_REM_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_REM_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17084_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17084_162_non_const_error))); goto __T268; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17084_380_non_const_min_t = 4294967295U; __cuda_local_var_17084_400_non_const_max_t = 0U; {  int i;
# 277 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T269;
 unsigned __T270;
# 277 "pipeline.cu"
__cuda_local_var_17084_380_non_const_min_t = ((__T269 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17084_380_non_const_min_t, __T269))); __cuda_local_var_17084_400_non_const_max_t = ((__T270 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17084_400_non_const_max_t, __T270))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17084_400_non_const_max_t - __cuda_local_var_17084_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17084_400_non_const_max_t - __cuda_local_var_17084_380_non_const_min_t)))); } while (0); __T268:;
do {  cudaError_t __cuda_local_var_17085_162_non_const_error;
# 278 "pipeline.cu"
 unsigned __cuda_local_var_17085_380_non_const_min_t;
# 278 "pipeline.cu"
 unsigned __cuda_local_var_17085_400_non_const_max_t;
# 278 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MIN_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17085_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17085_162_non_const_error))); goto __T271; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17085_380_non_const_min_t = 4294967295U; __cuda_local_var_17085_400_non_const_max_t = 0U; {  int i;
# 278 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T272;
 unsigned __T273;
# 278 "pipeline.cu"
__cuda_local_var_17085_380_non_const_min_t = ((__T272 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17085_380_non_const_min_t, __T272))); __cuda_local_var_17085_400_non_const_max_t = ((__T273 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17085_400_non_const_max_t, __T273))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17085_400_non_const_max_t - __cuda_local_var_17085_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17085_400_non_const_max_t - __cuda_local_var_17085_380_non_const_min_t)))); } while (0); __T271:;
do {  cudaError_t __cuda_local_var_17086_162_non_const_error;
# 279 "pipeline.cu"
 unsigned __cuda_local_var_17086_380_non_const_min_t;
# 279 "pipeline.cu"
 unsigned __cuda_local_var_17086_400_non_const_max_t;
# 279 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_MAX_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17086_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17086_162_non_const_error))); goto __T274; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17086_380_non_const_min_t = 4294967295U; __cuda_local_var_17086_400_non_const_max_t = 0U; {  int i;
# 279 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T275;
 unsigned __T276;
# 279 "pipeline.cu"
__cuda_local_var_17086_380_non_const_min_t = ((__T275 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17086_380_non_const_min_t, __T275))); __cuda_local_var_17086_400_non_const_max_t = ((__T276 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17086_400_non_const_max_t, __T276))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17086_400_non_const_max_t - __cuda_local_var_17086_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17086_400_non_const_max_t - __cuda_local_var_17086_380_non_const_min_t)))); } while (0); __T274:;
do {  cudaError_t __cuda_local_var_17087_162_non_const_error;
# 280 "pipeline.cu"
 unsigned __cuda_local_var_17087_380_non_const_min_t;
# 280 "pipeline.cu"
 unsigned __cuda_local_var_17087_400_non_const_max_t;
# 280 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ABS_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_ABS_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17087_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17087_162_non_const_error))); goto __T277; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17087_380_non_const_min_t = 4294967295U; __cuda_local_var_17087_400_non_const_max_t = 0U; {  int i;
# 280 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T278;
 unsigned __T279;
# 280 "pipeline.cu"
__cuda_local_var_17087_380_non_const_min_t = ((__T278 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17087_380_non_const_min_t, __T278))); __cuda_local_var_17087_400_non_const_max_t = ((__T279 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17087_400_non_const_max_t, __T279))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17087_400_non_const_max_t - __cuda_local_var_17087_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17087_400_non_const_max_t - __cuda_local_var_17087_380_non_const_min_t)))); } while (0); __T277:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17091_109_non_const_error;
# 284 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_ADD_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17091_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17091_109_non_const_error))); goto __T280; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T280:;
do {  cudaError_t __cuda_local_var_17092_109_non_const_error;
# 285 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_SUB_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17092_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17092_109_non_const_error))); goto __T281; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T281:;
do {  cudaError_t __cuda_local_var_17093_109_non_const_error;
# 286 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17093_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17093_109_non_const_error))); goto __T282; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T282:;
do {  cudaError_t __cuda_local_var_17094_109_non_const_error;
# 287 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17094_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17094_109_non_const_error))); goto __T283; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T283:;
do {  cudaError_t __cuda_local_var_17095_109_non_const_error;
# 288 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_DIV_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17095_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17095_109_non_const_error))); goto __T284; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T284:;
do {  cudaError_t __cuda_local_var_17096_109_non_const_error;
# 289 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MIN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17096_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17096_109_non_const_error))); goto __T285; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T285:;
do {  cudaError_t __cuda_local_var_17097_109_non_const_error;
# 290 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MAX_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17097_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17097_109_non_const_error))); goto __T286; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T286:;

do {  cudaError_t __cuda_local_var_17099_166_non_const_error;
# 292 "pipeline.cu"
 unsigned __cuda_local_var_17099_384_non_const_min_t;
# 292 "pipeline.cu"
 unsigned __cuda_local_var_17099_404_non_const_max_t;
# 292 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_ADD_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17099_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17099_166_non_const_error))); goto __T287; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17099_384_non_const_min_t = 4294967295U; __cuda_local_var_17099_404_non_const_max_t = 0U; {  int i;
# 292 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T288;
 unsigned __T289;
# 292 "pipeline.cu"
__cuda_local_var_17099_384_non_const_min_t = ((__T288 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17099_384_non_const_min_t, __T288))); __cuda_local_var_17099_404_non_const_max_t = ((__T289 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17099_404_non_const_max_t, __T289))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17099_404_non_const_max_t - __cuda_local_var_17099_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17099_404_non_const_max_t - __cuda_local_var_17099_384_non_const_min_t)))); } while (0); __T287:;
do {  cudaError_t __cuda_local_var_17100_166_non_const_error;
# 293 "pipeline.cu"
 unsigned __cuda_local_var_17100_384_non_const_min_t;
# 293 "pipeline.cu"
 unsigned __cuda_local_var_17100_404_non_const_max_t;
# 293 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_SUB_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17100_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17100_166_non_const_error))); goto __T290; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17100_384_non_const_min_t = 4294967295U; __cuda_local_var_17100_404_non_const_max_t = 0U; {  int i;
# 293 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T291;
 unsigned __T292;
# 293 "pipeline.cu"
__cuda_local_var_17100_384_non_const_min_t = ((__T291 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17100_384_non_const_min_t, __T291))); __cuda_local_var_17100_404_non_const_max_t = ((__T292 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17100_404_non_const_max_t, __T292))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17100_404_non_const_max_t - __cuda_local_var_17100_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17100_404_non_const_max_t - __cuda_local_var_17100_384_non_const_min_t)))); } while (0); __T290:;
do {  cudaError_t __cuda_local_var_17101_166_non_const_error;
# 294 "pipeline.cu"
 unsigned __cuda_local_var_17101_384_non_const_min_t;
# 294 "pipeline.cu"
 unsigned __cuda_local_var_17101_404_non_const_max_t;
# 294 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17101_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17101_166_non_const_error))); goto __T293; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17101_384_non_const_min_t = 4294967295U; __cuda_local_var_17101_404_non_const_max_t = 0U; {  int i;
# 294 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T294;
 unsigned __T295;
# 294 "pipeline.cu"
__cuda_local_var_17101_384_non_const_min_t = ((__T294 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17101_384_non_const_min_t, __T294))); __cuda_local_var_17101_404_non_const_max_t = ((__T295 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17101_404_non_const_max_t, __T295))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17101_404_non_const_max_t - __cuda_local_var_17101_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17101_404_non_const_max_t - __cuda_local_var_17101_384_non_const_min_t)))); } while (0); __T293:;
do {  cudaError_t __cuda_local_var_17102_166_non_const_error;
# 295 "pipeline.cu"
 unsigned __cuda_local_var_17102_384_non_const_min_t;
# 295 "pipeline.cu"
 unsigned __cuda_local_var_17102_404_non_const_max_t;
# 295 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17102_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17102_166_non_const_error))); goto __T296; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17102_384_non_const_min_t = 4294967295U; __cuda_local_var_17102_404_non_const_max_t = 0U; {  int i;
# 295 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T297;
 unsigned __T298;
# 295 "pipeline.cu"
__cuda_local_var_17102_384_non_const_min_t = ((__T297 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17102_384_non_const_min_t, __T297))); __cuda_local_var_17102_404_non_const_max_t = ((__T298 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17102_404_non_const_max_t, __T298))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17102_404_non_const_max_t - __cuda_local_var_17102_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17102_404_non_const_max_t - __cuda_local_var_17102_384_non_const_min_t)))); } while (0); __T296:;
do {  cudaError_t __cuda_local_var_17103_166_non_const_error;
# 296 "pipeline.cu"
 unsigned __cuda_local_var_17103_384_non_const_min_t;
# 296 "pipeline.cu"
 unsigned __cuda_local_var_17103_404_non_const_max_t;
# 296 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_DIV_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17103_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17103_166_non_const_error))); goto __T299; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17103_384_non_const_min_t = 4294967295U; __cuda_local_var_17103_404_non_const_max_t = 0U; {  int i;
# 296 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2100;
 unsigned __T2101;
# 296 "pipeline.cu"
__cuda_local_var_17103_384_non_const_min_t = ((__T2100 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17103_384_non_const_min_t, __T2100))); __cuda_local_var_17103_404_non_const_max_t = ((__T2101 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17103_404_non_const_max_t, __T2101))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17103_404_non_const_max_t - __cuda_local_var_17103_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17103_404_non_const_max_t - __cuda_local_var_17103_384_non_const_min_t)))); } while (0); __T299:;
do {  cudaError_t __cuda_local_var_17104_166_non_const_error;
# 297 "pipeline.cu"
 unsigned __cuda_local_var_17104_384_non_const_min_t;
# 297 "pipeline.cu"
 unsigned __cuda_local_var_17104_404_non_const_max_t;
# 297 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MIN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17104_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17104_166_non_const_error))); goto __T2102; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17104_384_non_const_min_t = 4294967295U; __cuda_local_var_17104_404_non_const_max_t = 0U; {  int i;
# 297 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2103;
 unsigned __T2104;
# 297 "pipeline.cu"
__cuda_local_var_17104_384_non_const_min_t = ((__T2103 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17104_384_non_const_min_t, __T2103))); __cuda_local_var_17104_404_non_const_max_t = ((__T2104 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17104_404_non_const_max_t, __T2104))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17104_404_non_const_max_t - __cuda_local_var_17104_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17104_404_non_const_max_t - __cuda_local_var_17104_384_non_const_min_t)))); } while (0); __T2102:;
do {  cudaError_t __cuda_local_var_17105_166_non_const_error;
# 298 "pipeline.cu"
 unsigned __cuda_local_var_17105_384_non_const_min_t;
# 298 "pipeline.cu"
 unsigned __cuda_local_var_17105_404_non_const_max_t;
# 298 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MAX_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17105_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17105_166_non_const_error))); goto __T2105; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17105_384_non_const_min_t = 4294967295U; __cuda_local_var_17105_404_non_const_max_t = 0U; {  int i;
# 298 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2106;
 unsigned __T2107;
# 298 "pipeline.cu"
__cuda_local_var_17105_384_non_const_min_t = ((__T2106 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17105_384_non_const_min_t, __T2106))); __cuda_local_var_17105_404_non_const_max_t = ((__T2107 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17105_404_non_const_max_t, __T2107))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17105_404_non_const_max_t - __cuda_local_var_17105_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17105_404_non_const_max_t - __cuda_local_var_17105_384_non_const_min_t)))); } while (0); __T2105:;
printf(((const char *)"\n"));



do {  cudaError_t __cuda_local_var_17110_110_non_const_error;
# 303 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17110_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17110_110_non_const_error))); goto __T2108; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2108:;
do {  cudaError_t __cuda_local_var_17111_110_non_const_error;
# 304 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SUB_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SUB_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17111_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17111_110_non_const_error))); goto __T2109; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2109:;
do {  cudaError_t __cuda_local_var_17112_110_non_const_error;
# 305 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MAD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAD_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17112_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17112_110_non_const_error))); goto __T2110; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2110:;
do {  cudaError_t __cuda_local_var_17113_110_non_const_error;
# 306 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MUL_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17113_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17113_110_non_const_error))); goto __T2111; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2111:;
do {  cudaError_t __cuda_local_var_17114_110_non_const_error;
# 307 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_DIV_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DIV_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17114_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17114_110_non_const_error))); goto __T2112; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2112:;
do {  cudaError_t __cuda_local_var_17115_110_non_const_error;
# 308 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MIN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MIN_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17115_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17115_110_non_const_error))); goto __T2113; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2113:;
do {  cudaError_t __cuda_local_var_17116_110_non_const_error;
# 309 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MAX_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MAX_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17116_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17116_110_non_const_error))); goto __T2114; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2114:;

do {  cudaError_t __cuda_local_var_17118_168_non_const_error;
# 311 "pipeline.cu"
 unsigned __cuda_local_var_17118_386_non_const_min_t;
# 311 "pipeline.cu"
 unsigned __cuda_local_var_17118_406_non_const_max_t;
# 311 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ADD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_ADD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17118_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17118_168_non_const_error))); goto __T2115; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17118_386_non_const_min_t = 4294967295U; __cuda_local_var_17118_406_non_const_max_t = 0U; {  int i;
# 311 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2116;
 unsigned __T2117;
# 311 "pipeline.cu"
__cuda_local_var_17118_386_non_const_min_t = ((__T2116 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17118_386_non_const_min_t, __T2116))); __cuda_local_var_17118_406_non_const_max_t = ((__T2117 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17118_406_non_const_max_t, __T2117))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17118_406_non_const_max_t - __cuda_local_var_17118_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17118_406_non_const_max_t - __cuda_local_var_17118_386_non_const_min_t)))); } while (0); __T2115:;
do {  cudaError_t __cuda_local_var_17119_168_non_const_error;
# 312 "pipeline.cu"
 unsigned __cuda_local_var_17119_386_non_const_min_t;
# 312 "pipeline.cu"
 unsigned __cuda_local_var_17119_406_non_const_max_t;
# 312 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SUB_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SUB_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17119_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17119_168_non_const_error))); goto __T2118; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17119_386_non_const_min_t = 4294967295U; __cuda_local_var_17119_406_non_const_max_t = 0U; {  int i;
# 312 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2119;
 unsigned __T2120;
# 312 "pipeline.cu"
__cuda_local_var_17119_386_non_const_min_t = ((__T2119 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17119_386_non_const_min_t, __T2119))); __cuda_local_var_17119_406_non_const_max_t = ((__T2120 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17119_406_non_const_max_t, __T2120))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17119_406_non_const_max_t - __cuda_local_var_17119_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17119_406_non_const_max_t - __cuda_local_var_17119_386_non_const_min_t)))); } while (0); __T2118:;
do {  cudaError_t __cuda_local_var_17120_168_non_const_error;
# 313 "pipeline.cu"
 unsigned __cuda_local_var_17120_386_non_const_min_t;
# 313 "pipeline.cu"
 unsigned __cuda_local_var_17120_406_non_const_max_t;
# 313 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MAD_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17120_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17120_168_non_const_error))); goto __T2121; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17120_386_non_const_min_t = 4294967295U; __cuda_local_var_17120_406_non_const_max_t = 0U; {  int i;
# 313 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2122;
 unsigned __T2123;
# 313 "pipeline.cu"
__cuda_local_var_17120_386_non_const_min_t = ((__T2122 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17120_386_non_const_min_t, __T2122))); __cuda_local_var_17120_406_non_const_max_t = ((__T2123 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17120_406_non_const_max_t, __T2123))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17120_406_non_const_max_t - __cuda_local_var_17120_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17120_406_non_const_max_t - __cuda_local_var_17120_386_non_const_min_t)))); } while (0); __T2121:;
do {  cudaError_t __cuda_local_var_17121_168_non_const_error;
# 314 "pipeline.cu"
 unsigned __cuda_local_var_17121_386_non_const_min_t;
# 314 "pipeline.cu"
 unsigned __cuda_local_var_17121_406_non_const_max_t;
# 314 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MUL_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17121_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17121_168_non_const_error))); goto __T2124; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17121_386_non_const_min_t = 4294967295U; __cuda_local_var_17121_406_non_const_max_t = 0U; {  int i;
# 314 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2125;
 unsigned __T2126;
# 314 "pipeline.cu"
__cuda_local_var_17121_386_non_const_min_t = ((__T2125 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17121_386_non_const_min_t, __T2125))); __cuda_local_var_17121_406_non_const_max_t = ((__T2126 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17121_406_non_const_max_t, __T2126))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17121_406_non_const_max_t - __cuda_local_var_17121_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17121_406_non_const_max_t - __cuda_local_var_17121_386_non_const_min_t)))); } while (0); __T2124:;
do {  cudaError_t __cuda_local_var_17122_168_non_const_error;
# 315 "pipeline.cu"
 unsigned __cuda_local_var_17122_386_non_const_min_t;
# 315 "pipeline.cu"
 unsigned __cuda_local_var_17122_406_non_const_max_t;
# 315 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DIV_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_DIV_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17122_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17122_168_non_const_error))); goto __T2127; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17122_386_non_const_min_t = 4294967295U; __cuda_local_var_17122_406_non_const_max_t = 0U; {  int i;
# 315 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2128;
 unsigned __T2129;
# 315 "pipeline.cu"
__cuda_local_var_17122_386_non_const_min_t = ((__T2128 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17122_386_non_const_min_t, __T2128))); __cuda_local_var_17122_406_non_const_max_t = ((__T2129 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17122_406_non_const_max_t, __T2129))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17122_406_non_const_max_t - __cuda_local_var_17122_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17122_406_non_const_max_t - __cuda_local_var_17122_386_non_const_min_t)))); } while (0); __T2127:;
do {  cudaError_t __cuda_local_var_17123_168_non_const_error;
# 316 "pipeline.cu"
 unsigned __cuda_local_var_17123_386_non_const_min_t;
# 316 "pipeline.cu"
 unsigned __cuda_local_var_17123_406_non_const_max_t;
# 316 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MIN_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MIN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17123_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17123_168_non_const_error))); goto __T2130; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17123_386_non_const_min_t = 4294967295U; __cuda_local_var_17123_406_non_const_max_t = 0U; {  int i;
# 316 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2131;
 unsigned __T2132;
# 316 "pipeline.cu"
__cuda_local_var_17123_386_non_const_min_t = ((__T2131 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17123_386_non_const_min_t, __T2131))); __cuda_local_var_17123_406_non_const_max_t = ((__T2132 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17123_406_non_const_max_t, __T2132))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17123_406_non_const_max_t - __cuda_local_var_17123_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17123_406_non_const_max_t - __cuda_local_var_17123_386_non_const_min_t)))); } while (0); __T2130:;
do {  cudaError_t __cuda_local_var_17124_168_non_const_error;
# 317 "pipeline.cu"
 unsigned __cuda_local_var_17124_386_non_const_min_t;
# 317 "pipeline.cu"
 unsigned __cuda_local_var_17124_406_non_const_max_t;
# 317 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAX_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_MAX_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17124_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17124_168_non_const_error))); goto __T2133; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17124_386_non_const_min_t = 4294967295U; __cuda_local_var_17124_406_non_const_max_t = 0U; {  int i;
# 317 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2134;
 unsigned __T2135;
# 317 "pipeline.cu"
__cuda_local_var_17124_386_non_const_min_t = ((__T2134 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17124_386_non_const_min_t, __T2134))); __cuda_local_var_17124_406_non_const_max_t = ((__T2135 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17124_406_non_const_max_t, __T2135))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17124_406_non_const_max_t - __cuda_local_var_17124_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17124_406_non_const_max_t - __cuda_local_var_17124_386_non_const_min_t)))); } while (0); __T2133:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17128_108_non_const_error;
# 321 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_AND_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_AND_UINT_DEP128"))); if (((int)(__cuda_local_var_17128_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17128_108_non_const_error))); goto __T2136; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2136:;
do {  cudaError_t __cuda_local_var_17129_107_non_const_error;
# 322 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_OR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_OR_UINT_DEP128"))); if (((int)(__cuda_local_var_17129_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17129_107_non_const_error))); goto __T2137; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2137:;
do {  cudaError_t __cuda_local_var_17130_108_non_const_error;
# 323 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_XOR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_XOR_UINT_DEP128"))); if (((int)(__cuda_local_var_17130_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17130_108_non_const_error))); goto __T2138; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2138:;
do {  cudaError_t __cuda_local_var_17131_108_non_const_error;
# 324 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SHL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SHL_UINT_DEP128"))); if (((int)(__cuda_local_var_17131_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17131_108_non_const_error))); goto __T2139; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2139:;
do {  cudaError_t __cuda_local_var_17132_108_non_const_error;
# 325 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SHR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SHR_UINT_DEP128"))); if (((int)(__cuda_local_var_17132_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17132_108_non_const_error))); goto __T2140; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2140:;

do {  cudaError_t __cuda_local_var_17134_164_non_const_error;
# 327 "pipeline.cu"
 unsigned __cuda_local_var_17134_382_non_const_min_t;
# 327 "pipeline.cu"
 unsigned __cuda_local_var_17134_402_non_const_max_t;
# 327 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_AND_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_AND_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17134_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17134_164_non_const_error))); goto __T2141; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17134_382_non_const_min_t = 4294967295U; __cuda_local_var_17134_402_non_const_max_t = 0U; {  int i;
# 327 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2142;
 unsigned __T2143;
# 327 "pipeline.cu"
__cuda_local_var_17134_382_non_const_min_t = ((__T2142 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17134_382_non_const_min_t, __T2142))); __cuda_local_var_17134_402_non_const_max_t = ((__T2143 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17134_402_non_const_max_t, __T2143))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17134_402_non_const_max_t - __cuda_local_var_17134_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17134_402_non_const_max_t - __cuda_local_var_17134_382_non_const_min_t)))); } while (0); __T2141:;
do {  cudaError_t __cuda_local_var_17135_162_non_const_error;
# 328 "pipeline.cu"
 unsigned __cuda_local_var_17135_380_non_const_min_t;
# 328 "pipeline.cu"
 unsigned __cuda_local_var_17135_400_non_const_max_t;
# 328 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_OR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_OR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17135_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17135_162_non_const_error))); goto __T2144; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17135_380_non_const_min_t = 4294967295U; __cuda_local_var_17135_400_non_const_max_t = 0U; {  int i;
# 328 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2145;
 unsigned __T2146;
# 328 "pipeline.cu"
__cuda_local_var_17135_380_non_const_min_t = ((__T2145 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17135_380_non_const_min_t, __T2145))); __cuda_local_var_17135_400_non_const_max_t = ((__T2146 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17135_400_non_const_max_t, __T2146))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17135_400_non_const_max_t - __cuda_local_var_17135_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17135_400_non_const_max_t - __cuda_local_var_17135_380_non_const_min_t)))); } while (0); __T2144:;
do {  cudaError_t __cuda_local_var_17136_164_non_const_error;
# 329 "pipeline.cu"
 unsigned __cuda_local_var_17136_382_non_const_min_t;
# 329 "pipeline.cu"
 unsigned __cuda_local_var_17136_402_non_const_max_t;
# 329 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_XOR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_XOR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17136_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17136_164_non_const_error))); goto __T2147; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17136_382_non_const_min_t = 4294967295U; __cuda_local_var_17136_402_non_const_max_t = 0U; {  int i;
# 329 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2148;
 unsigned __T2149;
# 329 "pipeline.cu"
__cuda_local_var_17136_382_non_const_min_t = ((__T2148 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17136_382_non_const_min_t, __T2148))); __cuda_local_var_17136_402_non_const_max_t = ((__T2149 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17136_402_non_const_max_t, __T2149))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17136_402_non_const_max_t - __cuda_local_var_17136_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17136_402_non_const_max_t - __cuda_local_var_17136_382_non_const_min_t)))); } while (0); __T2147:;
do {  cudaError_t __cuda_local_var_17137_164_non_const_error;
# 330 "pipeline.cu"
 unsigned __cuda_local_var_17137_382_non_const_min_t;
# 330 "pipeline.cu"
 unsigned __cuda_local_var_17137_402_non_const_max_t;
# 330 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SHL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SHL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17137_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17137_164_non_const_error))); goto __T2150; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17137_382_non_const_min_t = 4294967295U; __cuda_local_var_17137_402_non_const_max_t = 0U; {  int i;
# 330 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2151;
 unsigned __T2152;
# 330 "pipeline.cu"
__cuda_local_var_17137_382_non_const_min_t = ((__T2151 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17137_382_non_const_min_t, __T2151))); __cuda_local_var_17137_402_non_const_max_t = ((__T2152 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17137_402_non_const_max_t, __T2152))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17137_402_non_const_max_t - __cuda_local_var_17137_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17137_402_non_const_max_t - __cuda_local_var_17137_382_non_const_min_t)))); } while (0); __T2150:;
do {  cudaError_t __cuda_local_var_17138_164_non_const_error;
# 331 "pipeline.cu"
 unsigned __cuda_local_var_17138_382_non_const_min_t;
# 331 "pipeline.cu"
 unsigned __cuda_local_var_17138_402_non_const_max_t;
# 331 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SHR_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_SHR_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17138_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17138_164_non_const_error))); goto __T2153; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17138_382_non_const_min_t = 4294967295U; __cuda_local_var_17138_402_non_const_max_t = 0U; {  int i;
# 331 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2154;
 unsigned __T2155;
# 331 "pipeline.cu"
__cuda_local_var_17138_382_non_const_min_t = ((__T2154 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17138_382_non_const_min_t, __T2154))); __cuda_local_var_17138_402_non_const_max_t = ((__T2155 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17138_402_non_const_max_t, __T2155))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17138_402_non_const_max_t - __cuda_local_var_17138_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17138_402_non_const_max_t - __cuda_local_var_17138_382_non_const_min_t)))); } while (0); __T2153:;
printf(((const char *)"\n"));



do {  cudaError_t __cuda_local_var_17143_111_non_const_error;
# 336 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_UMUL24_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_UMUL24_UINT_DEP128"))); if (((int)(__cuda_local_var_17143_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17143_111_non_const_error))); goto __T2156; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2156:;
do {  cudaError_t __cuda_local_var_17144_109_non_const_error;
# 337 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL24_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MUL24_INT_DEP128"))); if (((int)(__cuda_local_var_17144_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17144_109_non_const_error))); goto __T2157; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2157:;
do {  cudaError_t __cuda_local_var_17145_111_non_const_error;
# 338 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_UMULHI_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_UMULHI_UINT_DEP128"))); if (((int)(__cuda_local_var_17145_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17145_111_non_const_error))); goto __T2158; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2158:;
do {  cudaError_t __cuda_local_var_17146_109_non_const_error;
# 339 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MULHI_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_MULHI_INT_DEP128"))); if (((int)(__cuda_local_var_17146_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17146_109_non_const_error))); goto __T2159; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2159:;
do {  cudaError_t __cuda_local_var_17147_109_non_const_error;
# 340 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_USAD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_USAD_UINT_DEP128"))); if (((int)(__cuda_local_var_17147_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17147_109_non_const_error))); goto __T2160; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2160:;
do {  cudaError_t __cuda_local_var_17148_107_non_const_error;
# 341 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_SAD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SAD_INT_DEP128"))); if (((int)(__cuda_local_var_17148_107_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17148_107_non_const_error))); goto __T2161; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2161:;

do {  cudaError_t __cuda_local_var_17150_170_non_const_error;
# 343 "pipeline.cu"
 unsigned __cuda_local_var_17150_388_non_const_min_t;
# 343 "pipeline.cu"
 unsigned __cuda_local_var_17150_408_non_const_max_t;
# 343 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_UMUL24_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_UMUL24_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17150_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17150_170_non_const_error))); goto __T2162; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17150_388_non_const_min_t = 4294967295U; __cuda_local_var_17150_408_non_const_max_t = 0U; {  int i;
# 343 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2163;
 unsigned __T2164;
# 343 "pipeline.cu"
__cuda_local_var_17150_388_non_const_min_t = ((__T2163 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17150_388_non_const_min_t, __T2163))); __cuda_local_var_17150_408_non_const_max_t = ((__T2164 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17150_408_non_const_max_t, __T2164))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17150_408_non_const_max_t - __cuda_local_var_17150_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17150_408_non_const_max_t - __cuda_local_var_17150_388_non_const_min_t)))); } while (0); __T2162:;
do {  cudaError_t __cuda_local_var_17151_166_non_const_error;
# 344 "pipeline.cu"
 unsigned __cuda_local_var_17151_384_non_const_min_t;
# 344 "pipeline.cu"
 unsigned __cuda_local_var_17151_404_non_const_max_t;
# 344 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL24_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL24_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17151_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17151_166_non_const_error))); goto __T2165; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17151_384_non_const_min_t = 4294967295U; __cuda_local_var_17151_404_non_const_max_t = 0U; {  int i;
# 344 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2166;
 unsigned __T2167;
# 344 "pipeline.cu"
__cuda_local_var_17151_384_non_const_min_t = ((__T2166 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17151_384_non_const_min_t, __T2166))); __cuda_local_var_17151_404_non_const_max_t = ((__T2167 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17151_404_non_const_max_t, __T2167))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17151_404_non_const_max_t - __cuda_local_var_17151_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17151_404_non_const_max_t - __cuda_local_var_17151_384_non_const_min_t)))); } while (0); __T2165:;
do {  cudaError_t __cuda_local_var_17152_170_non_const_error;
# 345 "pipeline.cu"
 unsigned __cuda_local_var_17152_388_non_const_min_t;
# 345 "pipeline.cu"
 unsigned __cuda_local_var_17152_408_non_const_max_t;
# 345 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_UMULHI_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_UMULHI_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17152_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17152_170_non_const_error))); goto __T2168; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17152_388_non_const_min_t = 4294967295U; __cuda_local_var_17152_408_non_const_max_t = 0U; {  int i;
# 345 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2169;
 unsigned __T2170;
# 345 "pipeline.cu"
__cuda_local_var_17152_388_non_const_min_t = ((__T2169 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17152_388_non_const_min_t, __T2169))); __cuda_local_var_17152_408_non_const_max_t = ((__T2170 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17152_408_non_const_max_t, __T2170))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17152_408_non_const_max_t - __cuda_local_var_17152_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17152_408_non_const_max_t - __cuda_local_var_17152_388_non_const_min_t)))); } while (0); __T2168:;
do {  cudaError_t __cuda_local_var_17153_166_non_const_error;
# 346 "pipeline.cu"
 unsigned __cuda_local_var_17153_384_non_const_min_t;
# 346 "pipeline.cu"
 unsigned __cuda_local_var_17153_404_non_const_max_t;
# 346 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MULHI_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MULHI_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17153_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17153_166_non_const_error))); goto __T2171; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17153_384_non_const_min_t = 4294967295U; __cuda_local_var_17153_404_non_const_max_t = 0U; {  int i;
# 346 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2172;
 unsigned __T2173;
# 346 "pipeline.cu"
__cuda_local_var_17153_384_non_const_min_t = ((__T2172 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17153_384_non_const_min_t, __T2172))); __cuda_local_var_17153_404_non_const_max_t = ((__T2173 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17153_404_non_const_max_t, __T2173))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17153_404_non_const_max_t - __cuda_local_var_17153_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17153_404_non_const_max_t - __cuda_local_var_17153_384_non_const_min_t)))); } while (0); __T2171:;
do {  cudaError_t __cuda_local_var_17154_166_non_const_error;
# 347 "pipeline.cu"
 unsigned __cuda_local_var_17154_384_non_const_min_t;
# 347 "pipeline.cu"
 unsigned __cuda_local_var_17154_404_non_const_max_t;
# 347 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_USAD_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_USAD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17154_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17154_166_non_const_error))); goto __T2174; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17154_384_non_const_min_t = 4294967295U; __cuda_local_var_17154_404_non_const_max_t = 0U; {  int i;
# 347 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2175;
 unsigned __T2176;
# 347 "pipeline.cu"
__cuda_local_var_17154_384_non_const_min_t = ((__T2175 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17154_384_non_const_min_t, __T2175))); __cuda_local_var_17154_404_non_const_max_t = ((__T2176 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17154_404_non_const_max_t, __T2176))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17154_404_non_const_max_t - __cuda_local_var_17154_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17154_404_non_const_max_t - __cuda_local_var_17154_384_non_const_min_t)))); } while (0); __T2174:;
do {  cudaError_t __cuda_local_var_17155_162_non_const_error;
# 348 "pipeline.cu"
 unsigned __cuda_local_var_17155_380_non_const_min_t;
# 348 "pipeline.cu"
 unsigned __cuda_local_var_17155_400_non_const_max_t;
# 348 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SAD_INT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z16K_SAD_INT_DEP128PjS_iii(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4, 6, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17155_162_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17155_162_non_const_error))); goto __T2177; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17155_380_non_const_min_t = 4294967295U; __cuda_local_var_17155_400_non_const_max_t = 0U; {  int i;
# 348 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2178;
 unsigned __T2179;
# 348 "pipeline.cu"
__cuda_local_var_17155_380_non_const_min_t = ((__T2178 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17155_380_non_const_min_t, __T2178))); __cuda_local_var_17155_400_non_const_max_t = ((__T2179 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17155_400_non_const_max_t, __T2179))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17155_400_non_const_max_t - __cuda_local_var_17155_380_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17155_400_non_const_max_t - __cuda_local_var_17155_380_non_const_min_t)))); } while (0); __T2177:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17159_113_non_const_error;
# 352 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FADD_RN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17159_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17159_113_non_const_error))); goto __T2180; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2180:;
do {  cudaError_t __cuda_local_var_17160_113_non_const_error;
# 353 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FADD_RZ_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17160_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17160_113_non_const_error))); goto __T2181; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2181:;
do {  cudaError_t __cuda_local_var_17161_113_non_const_error;
# 354 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FMUL_RN_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17161_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17161_113_non_const_error))); goto __T2182; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2182:;
do {  cudaError_t __cuda_local_var_17162_113_non_const_error;
# 355 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FMUL_RZ_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17162_113_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17162_113_non_const_error))); goto __T2183; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2183:;
do {  cudaError_t __cuda_local_var_17163_114_non_const_error;
# 356 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z23K_FDIVIDEF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FDIVIDEF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17163_114_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17163_114_non_const_error))); goto __T2184; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2184:;

do {  cudaError_t __cuda_local_var_17165_174_non_const_error;
# 358 "pipeline.cu"
 unsigned __cuda_local_var_17165_392_non_const_min_t;
# 358 "pipeline.cu"
 unsigned __cuda_local_var_17165_412_non_const_max_t;
# 358 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FADD_RN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17165_174_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17165_174_non_const_error))); goto __T2185; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17165_392_non_const_min_t = 4294967295U; __cuda_local_var_17165_412_non_const_max_t = 0U; {  int i;
# 358 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2186;
 unsigned __T2187;
# 358 "pipeline.cu"
__cuda_local_var_17165_392_non_const_min_t = ((__T2186 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17165_392_non_const_min_t, __T2186))); __cuda_local_var_17165_412_non_const_max_t = ((__T2187 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17165_412_non_const_max_t, __T2187))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17165_412_non_const_max_t - __cuda_local_var_17165_392_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17165_412_non_const_max_t - __cuda_local_var_17165_392_non_const_min_t)))); } while (0); __T2185:;
do {  cudaError_t __cuda_local_var_17166_174_non_const_error;
# 359 "pipeline.cu"
 unsigned __cuda_local_var_17166_392_non_const_min_t;
# 359 "pipeline.cu"
 unsigned __cuda_local_var_17166_412_non_const_max_t;
# 359 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FADD_RZ_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FADD_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17166_174_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17166_174_non_const_error))); goto __T2188; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17166_392_non_const_min_t = 4294967295U; __cuda_local_var_17166_412_non_const_max_t = 0U; {  int i;
# 359 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2189;
 unsigned __T2190;
# 359 "pipeline.cu"
__cuda_local_var_17166_392_non_const_min_t = ((__T2189 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17166_392_non_const_min_t, __T2189))); __cuda_local_var_17166_412_non_const_max_t = ((__T2190 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17166_412_non_const_max_t, __T2190))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17166_412_non_const_max_t - __cuda_local_var_17166_392_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17166_412_non_const_max_t - __cuda_local_var_17166_392_non_const_min_t)))); } while (0); __T2188:;
do {  cudaError_t __cuda_local_var_17167_174_non_const_error;
# 360 "pipeline.cu"
 unsigned __cuda_local_var_17167_392_non_const_min_t;
# 360 "pipeline.cu"
 unsigned __cuda_local_var_17167_412_non_const_max_t;
# 360 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FMUL_RN_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RN_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17167_174_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17167_174_non_const_error))); goto __T2191; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17167_392_non_const_min_t = 4294967295U; __cuda_local_var_17167_412_non_const_max_t = 0U; {  int i;
# 360 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2192;
 unsigned __T2193;
# 360 "pipeline.cu"
__cuda_local_var_17167_392_non_const_min_t = ((__T2192 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17167_392_non_const_min_t, __T2192))); __cuda_local_var_17167_412_non_const_max_t = ((__T2193 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17167_412_non_const_max_t, __T2193))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17167_412_non_const_max_t - __cuda_local_var_17167_392_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17167_412_non_const_max_t - __cuda_local_var_17167_392_non_const_min_t)))); } while (0); __T2191:;
do {  cudaError_t __cuda_local_var_17168_174_non_const_error;
# 361 "pipeline.cu"
 unsigned __cuda_local_var_17168_392_non_const_min_t;
# 361 "pipeline.cu"
 unsigned __cuda_local_var_17168_412_non_const_max_t;
# 361 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FMUL_RZ_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z22K_FMUL_RZ_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17168_174_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17168_174_non_const_error))); goto __T2194; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17168_392_non_const_min_t = 4294967295U; __cuda_local_var_17168_412_non_const_max_t = 0U; {  int i;
# 361 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2195;
 unsigned __T2196;
# 361 "pipeline.cu"
__cuda_local_var_17168_392_non_const_min_t = ((__T2195 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17168_392_non_const_min_t, __T2195))); __cuda_local_var_17168_412_non_const_max_t = ((__T2196 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17168_412_non_const_max_t, __T2196))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17168_412_non_const_max_t - __cuda_local_var_17168_392_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17168_412_non_const_max_t - __cuda_local_var_17168_392_non_const_min_t)))); } while (0); __T2194:;
do {  cudaError_t __cuda_local_var_17169_176_non_const_error;
# 362 "pipeline.cu"
 unsigned __cuda_local_var_17169_394_non_const_min_t;
# 362 "pipeline.cu"
 unsigned __cuda_local_var_17169_414_non_const_max_t;
# 362 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FDIVIDEF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z23K_FDIVIDEF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17169_176_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17169_176_non_const_error))); goto __T2197; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17169_394_non_const_min_t = 4294967295U; __cuda_local_var_17169_414_non_const_max_t = 0U; {  int i;
# 362 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2198;
 unsigned __T2199;
# 362 "pipeline.cu"
__cuda_local_var_17169_394_non_const_min_t = ((__T2198 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17169_394_non_const_min_t, __T2198))); __cuda_local_var_17169_414_non_const_max_t = ((__T2199 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17169_414_non_const_max_t, __T2199))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17169_414_non_const_max_t - __cuda_local_var_17169_394_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17169_414_non_const_max_t - __cuda_local_var_17169_394_non_const_min_t)))); } while (0); __T2197:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17173_114_non_const_error;
# 366 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z23K_DADD_RN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_DADD_RN_DOUBLE_DEP128"))); if (((int)(__cuda_local_var_17173_114_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17173_114_non_const_error))); goto __T2200; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2200:;

do {  cudaError_t __cuda_local_var_17175_176_non_const_error;
# 368 "pipeline.cu"
 unsigned __cuda_local_var_17175_394_non_const_min_t;
# 368 "pipeline.cu"
 unsigned __cuda_local_var_17175_414_non_const_max_t;
# 368 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_DADD_RN_DOUBLE_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z23K_DADD_RN_DOUBLE_DEP128PjS_ddi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0), (6.0), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17175_176_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17175_176_non_const_error))); goto __T2201; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17175_394_non_const_min_t = 4294967295U; __cuda_local_var_17175_414_non_const_max_t = 0U; {  int i;
# 368 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2202;
 unsigned __T2203;
# 368 "pipeline.cu"
__cuda_local_var_17175_394_non_const_min_t = ((__T2202 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17175_394_non_const_min_t, __T2202))); __cuda_local_var_17175_414_non_const_max_t = ((__T2203 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17175_414_non_const_max_t, __T2203))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17175_414_non_const_max_t - __cuda_local_var_17175_394_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17175_414_non_const_max_t - __cuda_local_var_17175_394_non_const_min_t)))); } while (0); __T2201:;
printf(((const char *)"\n"));



do {  cudaError_t __cuda_local_var_17180_109_non_const_error;
# 373 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_RCP_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RCP_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17180_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17180_109_non_const_error))); goto __T2204; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2204:;
do {  cudaError_t __cuda_local_var_17181_110_non_const_error;
# 374 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17181_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17181_110_non_const_error))); goto __T2205; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2205:;
do {  cudaError_t __cuda_local_var_17182_111_non_const_error;
# 375 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17182_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17182_111_non_const_error))); goto __T2206; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2206:;
# 389 "pipeline.cu"
do {  cudaError_t __cuda_local_var_17184_166_non_const_error;
# 389 "pipeline.cu"
 unsigned __cuda_local_var_17184_384_non_const_min_t;
# 389 "pipeline.cu"
 unsigned __cuda_local_var_17184_404_non_const_max_t;
# 389 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RCP_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_RCP_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17184_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17184_166_non_const_error))); goto __T2207; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17184_384_non_const_min_t = 4294967295U; __cuda_local_var_17184_404_non_const_max_t = 0U; {  int i;
# 389 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2208;
 unsigned __T2209;
# 389 "pipeline.cu"
__cuda_local_var_17184_384_non_const_min_t = ((__T2208 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17184_384_non_const_min_t, __T2208))); __cuda_local_var_17184_404_non_const_max_t = ((__T2209 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17184_404_non_const_max_t, __T2209))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17184_404_non_const_max_t - __cuda_local_var_17184_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17184_404_non_const_max_t - __cuda_local_var_17184_384_non_const_min_t)))); } while (0); __T2207:;
do {  cudaError_t __cuda_local_var_17185_168_non_const_error;
# 390 "pipeline.cu"
 unsigned __cuda_local_var_17185_386_non_const_min_t;
# 390 "pipeline.cu"
 unsigned __cuda_local_var_17185_406_non_const_max_t;
# 390 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17185_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17185_168_non_const_error))); goto __T2210; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17185_386_non_const_min_t = 4294967295U; __cuda_local_var_17185_406_non_const_max_t = 0U; {  int i;
# 390 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2211;
 unsigned __T2212;
# 390 "pipeline.cu"
__cuda_local_var_17185_386_non_const_min_t = ((__T2211 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17185_386_non_const_min_t, __T2211))); __cuda_local_var_17185_406_non_const_max_t = ((__T2212 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17185_406_non_const_max_t, __T2212))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17185_406_non_const_max_t - __cuda_local_var_17185_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17185_406_non_const_max_t - __cuda_local_var_17185_386_non_const_min_t)))); } while (0); __T2210:;
do {  cudaError_t __cuda_local_var_17186_170_non_const_error;
# 391 "pipeline.cu"
 unsigned __cuda_local_var_17186_388_non_const_min_t;
# 391 "pipeline.cu"
 unsigned __cuda_local_var_17186_408_non_const_max_t;
# 391 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_RSQRT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_RSQRT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17186_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17186_170_non_const_error))); goto __T2213; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17186_388_non_const_min_t = 4294967295U; __cuda_local_var_17186_408_non_const_max_t = 0U; {  int i;
# 391 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2214;
 unsigned __T2215;
# 391 "pipeline.cu"
__cuda_local_var_17186_388_non_const_min_t = ((__T2214 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17186_388_non_const_min_t, __T2214))); __cuda_local_var_17186_408_non_const_max_t = ((__T2215 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17186_408_non_const_max_t, __T2215))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17186_408_non_const_max_t - __cuda_local_var_17186_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17186_408_non_const_max_t - __cuda_local_var_17186_388_non_const_min_t)))); } while (0); __T2213:;
# 403 "pipeline.cu"
printf(((const char *)"\n"));



do {  cudaError_t __cuda_local_var_17192_110_non_const_error;
# 407 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SINF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SINF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17192_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17192_110_non_const_error))); goto __T2216; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2216:;
do {  cudaError_t __cuda_local_var_17193_110_non_const_error;
# 408 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_COSF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_COSF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17193_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17193_110_non_const_error))); goto __T2217; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2217:;
do {  cudaError_t __cuda_local_var_17194_110_non_const_error;
# 409 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_TANF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_TANF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17194_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17194_110_non_const_error))); goto __T2218; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2218:;
do {  cudaError_t __cuda_local_var_17195_110_non_const_error;
# 410 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_EXPF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXPF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17195_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17195_110_non_const_error))); goto __T2219; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2219:;
do {  cudaError_t __cuda_local_var_17196_111_non_const_error;
# 411 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_EXP2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXP2F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17196_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17196_111_non_const_error))); goto __T2220; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2220:;
do {  cudaError_t __cuda_local_var_17197_112_non_const_error;
# 412 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z21K_EXP10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_EXP10F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17197_112_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17197_112_non_const_error))); goto __T2221; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2221:;
do {  cudaError_t __cuda_local_var_17198_110_non_const_error;
# 413 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_LOGF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOGF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17198_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17198_110_non_const_error))); goto __T2222; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2222:;
do {  cudaError_t __cuda_local_var_17199_111_non_const_error;
# 414 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_LOG2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOG2F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17199_111_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17199_111_non_const_error))); goto __T2223; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2223:;
do {  cudaError_t __cuda_local_var_17200_112_non_const_error;
# 415 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z21K_LOG10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_LOG10F_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17200_112_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17200_112_non_const_error))); goto __T2224; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2224:;
do {  cudaError_t __cuda_local_var_17201_110_non_const_error;
# 416 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_POWF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_POWF_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17201_110_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17201_110_non_const_error))); goto __T2225; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2225:;

do {  cudaError_t __cuda_local_var_17203_168_non_const_error;
# 418 "pipeline.cu"
 unsigned __cuda_local_var_17203_386_non_const_min_t;
# 418 "pipeline.cu"
 unsigned __cuda_local_var_17203_406_non_const_max_t;
# 418 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SINF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_SINF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17203_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17203_168_non_const_error))); goto __T2226; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17203_386_non_const_min_t = 4294967295U; __cuda_local_var_17203_406_non_const_max_t = 0U; {  int i;
# 418 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2227;
 unsigned __T2228;
# 418 "pipeline.cu"
__cuda_local_var_17203_386_non_const_min_t = ((__T2227 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17203_386_non_const_min_t, __T2227))); __cuda_local_var_17203_406_non_const_max_t = ((__T2228 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17203_406_non_const_max_t, __T2228))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17203_406_non_const_max_t - __cuda_local_var_17203_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17203_406_non_const_max_t - __cuda_local_var_17203_386_non_const_min_t)))); } while (0); __T2226:;
do {  cudaError_t __cuda_local_var_17204_168_non_const_error;
# 419 "pipeline.cu"
 unsigned __cuda_local_var_17204_386_non_const_min_t;
# 419 "pipeline.cu"
 unsigned __cuda_local_var_17204_406_non_const_max_t;
# 419 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_COSF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_COSF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17204_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17204_168_non_const_error))); goto __T2229; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17204_386_non_const_min_t = 4294967295U; __cuda_local_var_17204_406_non_const_max_t = 0U; {  int i;
# 419 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2230;
 unsigned __T2231;
# 419 "pipeline.cu"
__cuda_local_var_17204_386_non_const_min_t = ((__T2230 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17204_386_non_const_min_t, __T2230))); __cuda_local_var_17204_406_non_const_max_t = ((__T2231 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17204_406_non_const_max_t, __T2231))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17204_406_non_const_max_t - __cuda_local_var_17204_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17204_406_non_const_max_t - __cuda_local_var_17204_386_non_const_min_t)))); } while (0); __T2229:;
do {  cudaError_t __cuda_local_var_17205_168_non_const_error;
# 420 "pipeline.cu"
 unsigned __cuda_local_var_17205_386_non_const_min_t;
# 420 "pipeline.cu"
 unsigned __cuda_local_var_17205_406_non_const_max_t;
# 420 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_TANF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_TANF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17205_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17205_168_non_const_error))); goto __T2232; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17205_386_non_const_min_t = 4294967295U; __cuda_local_var_17205_406_non_const_max_t = 0U; {  int i;
# 420 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2233;
 unsigned __T2234;
# 420 "pipeline.cu"
__cuda_local_var_17205_386_non_const_min_t = ((__T2233 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17205_386_non_const_min_t, __T2233))); __cuda_local_var_17205_406_non_const_max_t = ((__T2234 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17205_406_non_const_max_t, __T2234))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17205_406_non_const_max_t - __cuda_local_var_17205_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17205_406_non_const_max_t - __cuda_local_var_17205_386_non_const_min_t)))); } while (0); __T2232:;
do {  cudaError_t __cuda_local_var_17206_168_non_const_error;
# 421 "pipeline.cu"
 unsigned __cuda_local_var_17206_386_non_const_min_t;
# 421 "pipeline.cu"
 unsigned __cuda_local_var_17206_406_non_const_max_t;
# 421 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXPF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_EXPF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17206_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17206_168_non_const_error))); goto __T2235; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17206_386_non_const_min_t = 4294967295U; __cuda_local_var_17206_406_non_const_max_t = 0U; {  int i;
# 421 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2236;
 unsigned __T2237;
# 421 "pipeline.cu"
__cuda_local_var_17206_386_non_const_min_t = ((__T2236 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17206_386_non_const_min_t, __T2236))); __cuda_local_var_17206_406_non_const_max_t = ((__T2237 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17206_406_non_const_max_t, __T2237))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17206_406_non_const_max_t - __cuda_local_var_17206_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17206_406_non_const_max_t - __cuda_local_var_17206_386_non_const_min_t)))); } while (0); __T2235:;
do {  cudaError_t __cuda_local_var_17207_170_non_const_error;
# 422 "pipeline.cu"
 unsigned __cuda_local_var_17207_388_non_const_min_t;
# 422 "pipeline.cu"
 unsigned __cuda_local_var_17207_408_non_const_max_t;
# 422 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXP2F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_EXP2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17207_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17207_170_non_const_error))); goto __T2238; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17207_388_non_const_min_t = 4294967295U; __cuda_local_var_17207_408_non_const_max_t = 0U; {  int i;
# 422 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2239;
 unsigned __T2240;
# 422 "pipeline.cu"
__cuda_local_var_17207_388_non_const_min_t = ((__T2239 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17207_388_non_const_min_t, __T2239))); __cuda_local_var_17207_408_non_const_max_t = ((__T2240 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17207_408_non_const_max_t, __T2240))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17207_408_non_const_max_t - __cuda_local_var_17207_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17207_408_non_const_max_t - __cuda_local_var_17207_388_non_const_min_t)))); } while (0); __T2238:;
do {  cudaError_t __cuda_local_var_17208_172_non_const_error;
# 423 "pipeline.cu"
 unsigned __cuda_local_var_17208_390_non_const_min_t;
# 423 "pipeline.cu"
 unsigned __cuda_local_var_17208_410_non_const_max_t;
# 423 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_EXP10F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z21K_EXP10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17208_172_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17208_172_non_const_error))); goto __T2241; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17208_390_non_const_min_t = 4294967295U; __cuda_local_var_17208_410_non_const_max_t = 0U; {  int i;
# 423 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2242;
 unsigned __T2243;
# 423 "pipeline.cu"
__cuda_local_var_17208_390_non_const_min_t = ((__T2242 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17208_390_non_const_min_t, __T2242))); __cuda_local_var_17208_410_non_const_max_t = ((__T2243 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17208_410_non_const_max_t, __T2243))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17208_410_non_const_max_t - __cuda_local_var_17208_390_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17208_410_non_const_max_t - __cuda_local_var_17208_390_non_const_min_t)))); } while (0); __T2241:;
do {  cudaError_t __cuda_local_var_17209_168_non_const_error;
# 424 "pipeline.cu"
 unsigned __cuda_local_var_17209_386_non_const_min_t;
# 424 "pipeline.cu"
 unsigned __cuda_local_var_17209_406_non_const_max_t;
# 424 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOGF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_LOGF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17209_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17209_168_non_const_error))); goto __T2244; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17209_386_non_const_min_t = 4294967295U; __cuda_local_var_17209_406_non_const_max_t = 0U; {  int i;
# 424 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2245;
 unsigned __T2246;
# 424 "pipeline.cu"
__cuda_local_var_17209_386_non_const_min_t = ((__T2245 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17209_386_non_const_min_t, __T2245))); __cuda_local_var_17209_406_non_const_max_t = ((__T2246 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17209_406_non_const_max_t, __T2246))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17209_406_non_const_max_t - __cuda_local_var_17209_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17209_406_non_const_max_t - __cuda_local_var_17209_386_non_const_min_t)))); } while (0); __T2244:;
do {  cudaError_t __cuda_local_var_17210_170_non_const_error;
# 425 "pipeline.cu"
 unsigned __cuda_local_var_17210_388_non_const_min_t;
# 425 "pipeline.cu"
 unsigned __cuda_local_var_17210_408_non_const_max_t;
# 425 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOG2F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z20K_LOG2F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17210_170_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17210_170_non_const_error))); goto __T2247; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17210_388_non_const_min_t = 4294967295U; __cuda_local_var_17210_408_non_const_max_t = 0U; {  int i;
# 425 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2248;
 unsigned __T2249;
# 425 "pipeline.cu"
__cuda_local_var_17210_388_non_const_min_t = ((__T2248 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17210_388_non_const_min_t, __T2248))); __cuda_local_var_17210_408_non_const_max_t = ((__T2249 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17210_408_non_const_max_t, __T2249))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17210_408_non_const_max_t - __cuda_local_var_17210_388_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17210_408_non_const_max_t - __cuda_local_var_17210_388_non_const_min_t)))); } while (0); __T2247:;
do {  cudaError_t __cuda_local_var_17211_172_non_const_error;
# 426 "pipeline.cu"
 unsigned __cuda_local_var_17211_390_non_const_min_t;
# 426 "pipeline.cu"
 unsigned __cuda_local_var_17211_410_non_const_max_t;
# 426 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_LOG10F_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z21K_LOG10F_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17211_172_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17211_172_non_const_error))); goto __T2250; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17211_390_non_const_min_t = 4294967295U; __cuda_local_var_17211_410_non_const_max_t = 0U; {  int i;
# 426 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2251;
 unsigned __T2252;
# 426 "pipeline.cu"
__cuda_local_var_17211_390_non_const_min_t = ((__T2251 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17211_390_non_const_min_t, __T2251))); __cuda_local_var_17211_410_non_const_max_t = ((__T2252 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17211_410_non_const_max_t, __T2252))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17211_410_non_const_max_t - __cuda_local_var_17211_390_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17211_410_non_const_max_t - __cuda_local_var_17211_390_non_const_min_t)))); } while (0); __T2250:;
do {  cudaError_t __cuda_local_var_17212_168_non_const_error;
# 427 "pipeline.cu"
 unsigned __cuda_local_var_17212_386_non_const_min_t;
# 427 "pipeline.cu"
 unsigned __cuda_local_var_17212_406_non_const_max_t;
# 427 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_POWF_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z19K_POWF_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17212_168_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17212_168_non_const_error))); goto __T2253; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17212_386_non_const_min_t = 4294967295U; __cuda_local_var_17212_406_non_const_max_t = 0U; {  int i;
# 427 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2254;
 unsigned __T2255;
# 427 "pipeline.cu"
__cuda_local_var_17212_386_non_const_min_t = ((__T2254 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17212_386_non_const_min_t, __T2254))); __cuda_local_var_17212_406_non_const_max_t = ((__T2255 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17212_406_non_const_max_t, __T2255))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17212_406_non_const_max_t - __cuda_local_var_17212_386_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17212_406_non_const_max_t - __cuda_local_var_17212_386_non_const_min_t)))); } while (0); __T2253:;
printf(((const char *)"\n"));


do {  cudaError_t __cuda_local_var_17216_115_non_const_error;
# 431 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z24K_INTASFLOAT_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_INTASFLOAT_UINT_DEP128"))); if (((int)(__cuda_local_var_17216_115_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17216_115_non_const_error))); goto __T2256; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2256:;
do {  cudaError_t __cuda_local_var_17217_116_non_const_error;
# 432 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z25K_FLOATASINT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_FLOATASINT_FLOAT_DEP128"))); if (((int)(__cuda_local_var_17217_116_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17217_116_non_const_error))); goto __T2257; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2257:;

do {  cudaError_t __cuda_local_var_17219_178_non_const_error;
# 434 "pipeline.cu"
 unsigned __cuda_local_var_17219_396_non_const_min_t;
# 434 "pipeline.cu"
 unsigned __cuda_local_var_17219_416_non_const_max_t;
# 434 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_INTASFLOAT_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z24K_INTASFLOAT_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17219_178_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17219_178_non_const_error))); goto __T2258; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17219_396_non_const_min_t = 4294967295U; __cuda_local_var_17219_416_non_const_max_t = 0U; {  int i;
# 434 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2259;
 unsigned __T2260;
# 434 "pipeline.cu"
__cuda_local_var_17219_396_non_const_min_t = ((__T2259 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17219_396_non_const_min_t, __T2259))); __cuda_local_var_17219_416_non_const_max_t = ((__T2260 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17219_416_non_const_max_t, __T2260))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17219_416_non_const_max_t - __cuda_local_var_17219_396_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17219_416_non_const_max_t - __cuda_local_var_17219_396_non_const_min_t)))); } while (0); __T2258:;
do {  cudaError_t __cuda_local_var_17220_180_non_const_error;
# 435 "pipeline.cu"
 unsigned __cuda_local_var_17220_398_non_const_min_t;
# 435 "pipeline.cu"
 unsigned __cuda_local_var_17220_418_non_const_max_t;
# 435 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_FLOATASINT_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z25K_FLOATASINT_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17220_180_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17220_180_non_const_error))); goto __T2261; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17220_398_non_const_min_t = 4294967295U; __cuda_local_var_17220_418_non_const_max_t = 0U; {  int i;
# 435 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2262;
 unsigned __T2263;
# 435 "pipeline.cu"
__cuda_local_var_17220_398_non_const_min_t = ((__T2262 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17220_398_non_const_min_t, __T2262))); __cuda_local_var_17220_418_non_const_max_t = ((__T2263 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17220_418_non_const_max_t, __T2263))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17220_418_non_const_max_t - __cuda_local_var_17220_398_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17220_418_non_const_max_t - __cuda_local_var_17220_398_non_const_min_t)))); } while (0); __T2261:;
printf(((const char *)"\n"));



do {  cudaError_t __cuda_local_var_17225_109_non_const_error;
# 440 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_POPC_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_POPC_UINT_DEP128"))); if (((int)(__cuda_local_var_17225_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17225_109_non_const_error))); goto __T2264; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2264:;
do {  cudaError_t __cuda_local_var_17226_108_non_const_error;
# 441 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_CLZ_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_CLZ_UINT_DEP128"))); if (((int)(__cuda_local_var_17226_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17226_108_non_const_error))); goto __T2265; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2265:;
printf(((const char *)"\n"));

do {  cudaError_t __cuda_local_var_17229_166_non_const_error;
# 444 "pipeline.cu"
 unsigned __cuda_local_var_17229_384_non_const_min_t;
# 444 "pipeline.cu"
 unsigned __cuda_local_var_17229_404_non_const_max_t;
# 444 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_POPC_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_POPC_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17229_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17229_166_non_const_error))); goto __T2266; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17229_384_non_const_min_t = 4294967295U; __cuda_local_var_17229_404_non_const_max_t = 0U; {  int i;
# 444 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2267;
 unsigned __T2268;
# 444 "pipeline.cu"
__cuda_local_var_17229_384_non_const_min_t = ((__T2267 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17229_384_non_const_min_t, __T2267))); __cuda_local_var_17229_404_non_const_max_t = ((__T2268 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17229_404_non_const_max_t, __T2268))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17229_404_non_const_max_t - __cuda_local_var_17229_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17229_404_non_const_max_t - __cuda_local_var_17229_384_non_const_min_t)))); } while (0); __T2266:;
do {  cudaError_t __cuda_local_var_17230_164_non_const_error;
# 445 "pipeline.cu"
 unsigned __cuda_local_var_17230_382_non_const_min_t;
# 445 "pipeline.cu"
 unsigned __cuda_local_var_17230_402_non_const_max_t;
# 445 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_CLZ_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_CLZ_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17230_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17230_164_non_const_error))); goto __T2269; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17230_382_non_const_min_t = 4294967295U; __cuda_local_var_17230_402_non_const_max_t = 0U; {  int i;
# 445 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2270;
 unsigned __T2271;
# 445 "pipeline.cu"
__cuda_local_var_17230_382_non_const_min_t = ((__T2270 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17230_382_non_const_min_t, __T2270))); __cuda_local_var_17230_402_non_const_max_t = ((__T2271 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17230_402_non_const_max_t, __T2271))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17230_402_non_const_max_t - __cuda_local_var_17230_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17230_402_non_const_max_t - __cuda_local_var_17230_382_non_const_min_t)))); } while (0); __T2269:;
printf(((const char *)"\n"));




do {  cudaError_t __cuda_local_var_17236_108_non_const_error;
# 451 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ALL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ALL_UINT_DEP128"))); if (((int)(__cuda_local_var_17236_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17236_108_non_const_error))); goto __T2272; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2272:;
do {  cudaError_t __cuda_local_var_17237_108_non_const_error;
# 452 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ANY_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_ANY_UINT_DEP128"))); if (((int)(__cuda_local_var_17237_108_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17237_108_non_const_error))); goto __T2273; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2273:;
do {  cudaError_t __cuda_local_var_17238_109_non_const_error;
# 453 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1U; (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_SYNC_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SYNC_UINT_DEP128"))); if (((int)(__cuda_local_var_17238_109_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17238_109_non_const_error))); goto __T2274; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2274:;
printf(((const char *)"\n"));

do {  cudaError_t __cuda_local_var_17241_164_non_const_error;
# 456 "pipeline.cu"
 unsigned __cuda_local_var_17241_382_non_const_min_t;
# 456 "pipeline.cu"
 unsigned __cuda_local_var_17241_402_non_const_max_t;
# 456 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ALL_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ALL_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17241_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17241_164_non_const_error))); goto __T2275; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17241_382_non_const_min_t = 4294967295U; __cuda_local_var_17241_402_non_const_max_t = 0U; {  int i;
# 456 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2276;
 unsigned __T2277;
# 456 "pipeline.cu"
__cuda_local_var_17241_382_non_const_min_t = ((__T2276 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17241_382_non_const_min_t, __T2276))); __cuda_local_var_17241_402_non_const_max_t = ((__T2277 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17241_402_non_const_max_t, __T2277))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17241_402_non_const_max_t - __cuda_local_var_17241_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17241_402_non_const_max_t - __cuda_local_var_17241_382_non_const_min_t)))); } while (0); __T2275:;
do {  cudaError_t __cuda_local_var_17242_164_non_const_error;
# 457 "pipeline.cu"
 unsigned __cuda_local_var_17242_382_non_const_min_t;
# 457 "pipeline.cu"
 unsigned __cuda_local_var_17242_402_non_const_max_t;
# 457 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_ANY_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ANY_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17242_164_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17242_164_non_const_error))); goto __T2278; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17242_382_non_const_min_t = 4294967295U; __cuda_local_var_17242_402_non_const_max_t = 0U; {  int i;
# 457 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2279;
 unsigned __T2280;
# 457 "pipeline.cu"
__cuda_local_var_17242_382_non_const_min_t = ((__T2279 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17242_382_non_const_min_t, __T2279))); __cuda_local_var_17242_402_non_const_max_t = ((__T2280 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17242_402_non_const_max_t, __T2280))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17242_402_non_const_max_t - __cuda_local_var_17242_382_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17242_402_non_const_max_t - __cuda_local_var_17242_382_non_const_min_t)))); } while (0); __T2278:;
do {  cudaError_t __cuda_local_var_17243_166_non_const_error;
# 458 "pipeline.cu"
 unsigned __cuda_local_var_17243_384_non_const_min_t;
# 458 "pipeline.cu"
 unsigned __cuda_local_var_17243_404_non_const_max_t;
# 458 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_SYNC_UINT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_SYNC_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17243_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17243_166_non_const_error))); goto __T2281; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17243_384_non_const_min_t = 4294967295U; __cuda_local_var_17243_404_non_const_max_t = 0U; {  int i;
# 458 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2282;
 unsigned __T2283;
# 458 "pipeline.cu"
__cuda_local_var_17243_384_non_const_min_t = ((__T2282 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17243_384_non_const_min_t, __T2282))); __cuda_local_var_17243_404_non_const_max_t = ((__T2283 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17243_404_non_const_max_t, __T2283))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17243_404_non_const_max_t - __cuda_local_var_17243_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17243_404_non_const_max_t - __cuda_local_var_17243_384_non_const_min_t)))); } while (0); __T2281:;
printf(((const char *)"\n"));


do { printf(((const char *)"\nPipeline latency/throughput with multiple warps (200 iterations of %d ops)\n"), 256); printf(((const char *)"  %s:\n"), ((const char *)("K_ADD_UINT_DEP128"))); for ((__cuda_local_var_17018_11_non_const_Db.x) = 1U; ((__cuda_local_var_17018_11_non_const_Db.x) <= 512U); (__cuda_local_var_17018_11_non_const_Db.x) += ((unsigned)(((__cuda_local_var_17018_11_non_const_Db.x) < 4U) ? 1 : (((__cuda_local_var_17018_11_non_const_Db.x) < 8U) ? 2 : (((__cuda_local_var_17018_11_non_const_Db.x) < 32U) ? 8 : 32))))) {  unsigned __cuda_local_var_17247_256_non_const_histogram[1024];
# 462 "pipeline.cu"
 unsigned __cuda_local_var_17247_292_non_const_sum_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_17247_319_non_const_max_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_17247_342_non_const_min_time;
# 462 "pipeline.cu"
 unsigned __cuda_local_var_17247_365_non_const_sum_max_time;
# 462 "pipeline.cu"
 char __cuda_local_var_17247_388_non_const_failed;
# 462 "pipeline.cu"
memset((char *)&__cuda_local_var_17247_256_non_const_histogram, 0,sizeof(__cuda_local_var_17247_256_non_const_histogram)); __cuda_local_var_17247_256_non_const_histogram[0] = 0U; __cuda_local_var_17247_292_non_const_sum_time = 0U; __cuda_local_var_17247_365_non_const_sum_max_time = 0U; __cuda_local_var_17247_388_non_const_failed = ((char)0); {  int i;
# 462 "pipeline.cu"
i = 0; for (; ((i < 200) && (!(__cuda_local_var_17247_388_non_const_failed))); i++) { cudaGetLastError(); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z17K_ADD_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); if (((int)(cudaGetLastError())) != 0) { __cuda_local_var_17247_388_non_const_failed = ((char)1); goto __T2284; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17247_319_non_const_max_time = 0U; __cuda_local_var_17247_342_non_const_min_time = 4294967295U; {  int j;
# 462 "pipeline.cu"
j = 0; for (; (((unsigned)j) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); j += 64) {  unsigned __T2285;
 unsigned __T2286;
# 462 "pipeline.cu"
__cuda_local_var_17247_292_non_const_sum_time += (((__cuda_local_var_17013_15_non_const_ts)[(j + 1)]) - ((__cuda_local_var_17013_15_non_const_ts)[j])); __cuda_local_var_17247_319_non_const_max_time = ((__T2285 = ((__cuda_local_var_17013_15_non_const_ts)[(j + 1)])) , (umax(__cuda_local_var_17247_319_non_const_max_time, __T2285))); __cuda_local_var_17247_342_non_const_min_time = ((__T2286 = ((__cuda_local_var_17013_15_non_const_ts)[j])) , (umin(__cuda_local_var_17247_342_non_const_min_time, __T2286))); ((__cuda_local_var_17247_256_non_const_histogram)[((((__cuda_local_var_17013_15_non_const_ts)[(j + 1)]) - ((__cuda_local_var_17013_15_non_const_ts)[j])) / 256U)])++; } } __cuda_local_var_17247_365_non_const_sum_max_time += (__cuda_local_var_17247_319_non_const_max_time - __cuda_local_var_17247_342_non_const_min_time); } } __T2284:; if (__cuda_local_var_17247_388_non_const_failed) { printf(((const char *)"    %2d warp%c (%3d thread%c)  failed."), (((__cuda_local_var_17018_11_non_const_Db.x) + 31U) / 32U), ((int)(((__cuda_local_var_17018_11_non_const_Db.x) >= 64U) ? ((char)115) : ((char)32))), (__cuda_local_var_17018_11_non_const_Db.x), ((int)(((__cuda_local_var_17018_11_non_const_Db.x) > 1U) ? ((char)115) : ((char)32)))); } else  { printf(((const char *)"    %2d warp%c (%3d thr) %9u clk (%.3f clk/warp, %.3f ops/clk) "), (((__cuda_local_var_17018_11_non_const_Db.x) + 31U) / 32U), ((int)(((__cuda_local_var_17018_11_non_const_Db.x) >= 64U) ? ((char)115) : ((char)32))), (__cuda_local_var_17018_11_non_const_Db.x), __cuda_local_var_17247_365_non_const_sum_max_time, (((((double)__cuda_local_var_17247_292_non_const_sum_time) / (200.0)) / (256.0)) / ((double)(((__cuda_local_var_17018_11_non_const_Db.x) + 31U) / 32U))), (((51200.0) * ((double)(__cuda_local_var_17018_11_non_const_Db.x))) / ((double)__cuda_local_var_17247_365_non_const_sum_max_time))); printf(((const char *)"  Histogram { ")); {  int i;
# 462 "pipeline.cu"
i = 0; for (; (i < 1024); i++) { if (((__cuda_local_var_17247_256_non_const_histogram)[i]) != 0U) { printf(((const char *)"(%d: %d) "), i, ((__cuda_local_var_17247_256_non_const_histogram)[i])); } } } printf(((const char *)"}")); } printf(((const char *)"\n")); } printf(((const char *)"\n")); } while (0);
printf(((const char *)"\n"));


printf(((const char *)"Trying various combinations of MUL and MAD to test dual issue:\n"));
do {  cudaError_t __cuda_local_var_17252_166_non_const_error;
# 467 "pipeline.cu"
 unsigned __cuda_local_var_17252_384_non_const_min_t;
# 467 "pipeline.cu"
 unsigned __cuda_local_var_17252_404_non_const_max_t;
# 467 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MUL_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MUL_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17252_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17252_166_non_const_error))); goto __T2287; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17252_384_non_const_min_t = 4294967295U; __cuda_local_var_17252_404_non_const_max_t = 0U; {  int i;
# 467 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2288;
 unsigned __T2289;
# 467 "pipeline.cu"
__cuda_local_var_17252_384_non_const_min_t = ((__T2288 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17252_384_non_const_min_t, __T2288))); __cuda_local_var_17252_404_non_const_max_t = ((__T2289 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17252_404_non_const_max_t, __T2289))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17252_404_non_const_max_t - __cuda_local_var_17252_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17252_404_non_const_max_t - __cuda_local_var_17252_384_non_const_min_t)))); } while (0); __T2287:;
do {  cudaError_t __cuda_local_var_17253_166_non_const_error;
# 468 "pipeline.cu"
 unsigned __cuda_local_var_17253_384_non_const_min_t;
# 468 "pipeline.cu"
 unsigned __cuda_local_var_17253_404_non_const_max_t;
# 468 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("K_MAD_FLOAT_DEP128"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_MAD_FLOAT_DEP128PjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17253_166_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17253_166_non_const_error))); goto __T2290; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17253_384_non_const_min_t = 4294967295U; __cuda_local_var_17253_404_non_const_max_t = 0U; {  int i;
# 468 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2291;
 unsigned __T2292;
# 468 "pipeline.cu"
__cuda_local_var_17253_384_non_const_min_t = ((__T2291 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17253_384_non_const_min_t, __T2291))); __cuda_local_var_17253_404_non_const_max_t = ((__T2292 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17253_404_non_const_max_t, __T2292))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17253_404_non_const_max_t - __cuda_local_var_17253_384_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17253_404_non_const_max_t - __cuda_local_var_17253_384_non_const_min_t)))); } while (0); __T2290:;
do {  cudaError_t __cuda_local_var_17254_146_non_const_error;
# 469 "pipeline.cu"
 unsigned __cuda_local_var_17254_364_non_const_min_t;
# 469 "pipeline.cu"
 unsigned __cuda_local_var_17254_384_non_const_max_t;
# 469 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = 1024U; printf(((const char *)"  %s \tthroughput:\t"), ((const char *)("KMAD_MUL"))); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z8KMAD_MULPjS_ffi(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, (4.0F), (6.0F), 2)); cudaThreadSynchronize(); if (((int)(__cuda_local_var_17254_146_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17254_146_non_const_error))); goto __T2293; } cudaThreadSynchronize(); cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); __cuda_local_var_17254_364_non_const_min_t = 4294967295U; __cuda_local_var_17254_384_non_const_max_t = 0U; {  int i;
# 469 "pipeline.cu"
i = 0; for (; (((unsigned)i) < ((__cuda_local_var_17018_11_non_const_Db.x) * 2U)); i++) {  unsigned __T2294;
 unsigned __T2295;
# 469 "pipeline.cu"
__cuda_local_var_17254_364_non_const_min_t = ((__T2294 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umin(__cuda_local_var_17254_364_non_const_min_t, __T2294))); __cuda_local_var_17254_384_non_const_max_t = ((__T2295 = ((__cuda_local_var_17013_15_non_const_ts)[i])) , (umax(__cuda_local_var_17254_384_non_const_max_t, __T2295))); } } printf(((const char *)"%9u clk (%.3f ops/clk)\n"), (__cuda_local_var_17254_384_non_const_max_t - __cuda_local_var_17254_364_non_const_min_t), (((double)((__cuda_local_var_17018_11_non_const_Db.x) * 256U)) / ((double)(__cuda_local_var_17254_384_non_const_max_t - __cuda_local_var_17254_364_non_const_min_t)))); } while (0); __T2293:;
printf(((const char *)"\n"));



printf(((const char *)"Measuring latency of syncthreads with multiple warps running:\n")); {
 int i;
# 475 "pipeline.cu"
i = 1; for (; (i <= 16); i++)
{
printf(((const char *)"%d warps: "), i);
do {  cudaError_t __cuda_local_var_17263_115_non_const_error;
# 478 "pipeline.cu"
(__cuda_local_var_17018_11_non_const_Db.x) = ((unsigned)(i * 32)); (cudaConfigureCall(__cuda_local_var_17019_11_non_const_Dg, __cuda_local_var_17018_11_non_const_Db, 0UL, ((cudaStream_t)0LL))) ? ((void)0) : (__device_stub__Z18K_SYNC_UINT_DEP128PjS_jji(__cuda_local_var_17014_16_non_const_d_ts, __cuda_local_var_17015_16_non_const_d_out, 4U, 6U, 2)); cudaThreadSynchronize(); printf(((const char *)"  %s \tlatency:    \t"), ((const char *)("K_SYNC_UINT_DEP128"))); if (((int)(__cuda_local_var_17263_115_non_const_error = (cudaGetLastError()))) != 0) { printf(((const char *)"  failed. %s\n\n"), (cudaGetErrorString(__cuda_local_var_17263_115_non_const_error))); goto __T2296; } cudaMemcpy(((void *)(__cuda_local_var_17013_15_non_const_ts)), ((const void *)__cuda_local_var_17014_16_non_const_d_ts), 8192UL, cudaMemcpyDeviceToHost); cudaThreadSynchronize(); printf(((const char *)"%u clk (%.3f clk/warp)\n"), (((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0])), (((double)(((__cuda_local_var_17013_15_non_const_ts)[1]) - ((__cuda_local_var_17013_15_non_const_ts)[0]))) / (256.0))); } while (0); __T2296:;
} }

cudaFree(((void *)__cuda_local_var_17014_16_non_const_d_ts));
cudaFree(((void *)__cuda_local_var_17015_16_non_const_d_out)); 

}
static void __sti___16_pipeline_cpp1_ii_00c5b4ce(void) {   }

#include "pipeline.cudafe1.stub.c"
